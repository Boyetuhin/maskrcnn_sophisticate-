{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "\n",
    "import annonutils\n",
    "import common\n",
    "import db_to_aids as db2a\n",
    "from _log_ import logcfg\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "logging.config.dictConfig(logcfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-08 10:46:53,864:[INFO]:[__main__]:[<ipython-input-2-50d89f1a0cde>:6 -             <module>() ]: datacfg:{'created_on': None, 'modified_on': None, 'timestamp': None, 'anndb_id': None, 'rel_id': None, 'dbname': None, 'dbid': None, 'allowed_file_type': ['.txt', '.csv', '.yml', '.json'], 'allowed_image_type': ['.pdf', '.png', '.jpg', '.jpeg', '.gif'], 'allowed_video_type': ['.mp4'], 'dataset': {}, 'load_data_from_file': False, 'train': [], 'evaluate': [], 'predict': [], 'publish': [], 'report': [], 'description': 'HD Map Dataset', 'files': {}, 'id': 'hmd', 'name': 'hmd', 'problem_id': 'hmd', 'annon_type': 'hmd', 'dataclass': 'HmdDataset', 'classes': '', 'class_ids': None, 'class_map': None, 'num_classes': None, 'splits': None, 'stats': {}, 'data_read_threshold': -1, 'db_dir': None, 'return_hmd': None, 'train_mode': 'training', 'test_mode': 'inference'}\n"
     ]
    }
   ],
   "source": [
    "datacfg = db2a.dbcfg\n",
    "cfg = db2a.appcfg\n",
    "get_annon_data = db2a.get_annon_data\n",
    "do_aids_split = db2a.do_aids_split\n",
    "\n",
    "log.info(\"datacfg:{}\".format(datacfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBCFG = cfg['DBCFG']\n",
    "mclient = MongoClient('mongodb://'+DBCFG['HOST']+':'+str(DBCFG['PORT']))\n",
    "db = mclient[DBCFG['DBNAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep the master list of row indices (image) which has been processed\n",
    "already_processed_indices = np.array([], dtype='int32')\n",
    "splited_indices = {}\n",
    "\n",
    "## percentage split between train and val data; remaining is the test data\n",
    "prcntg = np.array([.7,.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-08 10:52:04,644:[INFO]:[__main__]:[<ipython-input-9-f4fc9e2ff579>:6 -             <module>() ]: len(images): 30\n",
      "2019-10-08 10:52:04,646:[INFO]:[__main__]:[<ipython-input-9-f4fc9e2ff579>:16 -             <module>() ]: len(lbl_ids): 6\n",
      "2019-10-08 10:52:04,646:[INFO]:[__main__]:[<ipython-input-9-f4fc9e2ff579>:17 -             <module>() ]: lbl_ids: ['lane_marking', 'signage', 'road_polygon', 'loose_material', 'traffic_sign', 'traffic_sign_frame']\n"
     ]
    }
   ],
   "source": [
    "## Get Images and Classinfo (categories/labels)\n",
    "tblname = annonutils.get_tblname('IMAGES')\n",
    "collection = db.get_collection(tblname)\n",
    "\n",
    "images = np.array(list(collection.find({}, {'_id':False})))\n",
    "log.info(\"len(images): {}\".format(len(images)))\n",
    "# log.info(images)\n",
    "\n",
    "tblname = annonutils.get_tblname('CLASSINFO')\n",
    "collection = db.get_collection(tblname)\n",
    "cur = list(collection.find({}, {'_id':False}))\n",
    "lbl_ids = []\n",
    "for item in cur:\n",
    "    lbl_ids.append(item['lbl_id'])\n",
    "\n",
    "log.info('len(lbl_ids): {}'.format(len(lbl_ids[1:])))\n",
    "log.info('lbl_ids: {}'.format(lbl_ids[1:]))\n",
    "\n",
    "lbl_ids[1:] = np.sort(lbl_ids[1:])\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-27 23:52:45,808:[INFO]:[__main__]:[<ipython-input-47-1b94b120dee7>:18 -             <module>() ]: len(images): 85\n",
      "<filter object at 0x7fb894342978>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## filter specific labels\n",
    "AIDS_FILTER = {\n",
    "    'LABELS':[]\n",
    "    ,'RATIO':0\n",
    "    ,'BY':['annotation_per_label','image_per_label']\n",
    "    ,'ON':'annotation_per_label'\n",
    "}\n",
    "tblname = annonutils.get_tblname('IMAGES')\n",
    "collection = db.get_collection(tblname)\n",
    "\n",
    "labels = [\"signage\"]\n",
    "labels = [\"footpath_polygon\"]\n",
    "query = {}\n",
    "query = {\"lbl_ids\": { \"$in\": labels }}\n",
    "\n",
    "images = np.array(list(collection.find(query, {'_id':False})))\n",
    "\n",
    "log.info(\"len(images): {}\".format(len(images)))\n",
    "# log.info(\"images: {}\".format(images))\n",
    "\n",
    "lbl_ids = images[0]['lbl_ids']\n",
    "lbl_ids.index(labels[0])\n",
    "print(filter(lambda x: labels in x, images[0]['lbl_ids']))\n",
    "\n",
    "[lbl_ids.]\n",
    "# images['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['footpath_polygon', 'barricade', 'signage', 'traffic_sign', 'traffic_light']\n"
     ]
    }
   ],
   "source": [
    "## https://stackoverflow.com/questions/17506163/how-to-convert-a-boolean-array-to-an-int-array\n",
    "## https://stackoverflow.com/questions/20373039/how-do-i-convert-a-numpy-matrix-into-a-boolean-matrix\n",
    "\n",
    "tensor = np.zeros([len(images), len(lbl_ids[1:])], int)\n",
    "lbls = OrderedDict({j:0 for i, j in enumerate(lbl_ids[1:])})\n",
    "for j, image in enumerate(images):\n",
    "    labels_all = lbls.copy()\n",
    "    for l in image['lbl_ids']:\n",
    "        labels_all[l] += 1\n",
    "    label_cols = list(labels_all.values())\n",
    "    tensor[j,:] = label_cols\n",
    "\n",
    "# print(\"{}\".format(tensor))\n",
    "# print(np.array(tensor, dtype=bool))\n",
    "\n",
    "labels = list(lbls.keys())\n",
    "print(\"{}\".format(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_db_split(tensor, labels, splited_indices, already_processed_indices, prcntg):\n",
    "    print(\"--------------------------------------->\")\n",
    "    print(\"tensor.shape: {}\\nlabels to be processed: {}\\nalready_processed_indices: {}\\nprcntg: {}\".format(tensor.shape, labels, already_processed_indices, prcntg))\n",
    "\n",
    "    dd = np.array(tensor != 0, dtype=int)\n",
    "    total_images_per_label, total_label_per_image = np.sum(dd, axis=0), np.sum(dd, axis=1)\n",
    "    total_duplications_in_image = np.sum(np.sum(dd, axis=1)) - len(np.sum(dd, axis=1))\n",
    "    total_labels, total_annotations_per_label = len(np.sum(tensor, axis=0)), np.sum(tensor, axis=0)\n",
    "    total_annotations = np.sum(np.sum(tensor, axis=0))\n",
    "    total_images, total_annotations_per_image = len(np.sum(tensor, axis=1)), np.sum(tensor, axis=1)\n",
    "\n",
    "    print(\"Total Images per Label: {}\\nTotal Label per Image: {}\".format(total_images_per_label, total_label_per_image))\n",
    "    print(\"Total Duplication in Images: {}\".format(total_duplications_in_image))\n",
    "    print(\"Total Labels: {}\\nTotal Annotations per Label: {}\".format(total_labels, total_annotations_per_label))\n",
    "    print(\"Total Annotations: {}\".format(total_annotations))\n",
    "    print(\"Total Images: {}\\nTotal Annotations per Image: {}\".format(total_images, total_annotations_per_image))\n",
    "    \n",
    "    if total_images > 0 and len(labels) > 0:\n",
    "        print(\"total_images_per_label: {}\".format(total_images_per_label))\n",
    "        total_images_per_label_sorted_index = np.argsort(total_images_per_label)\n",
    "        print(\"total_images_per_label_sorted_index: {}\".format(total_images_per_label_sorted_index))\n",
    "\n",
    "        ## index_of_min_total_images_per_label\n",
    "        index = total_images_per_label_sorted_index[0]\n",
    "        print(\"total_images_per_label[index]: {}\".format(total_images_per_label[index]))\n",
    "\n",
    "        ## column values for the given index_of_min_total_images_per_label\n",
    "        index_col_vals = tensor[:,index]\n",
    "        print(\"index_col_vals: {}\".format(index_col_vals))\n",
    "\n",
    "        label = labels[index]\n",
    "        print(\"label: {}\".format(label))\n",
    "\n",
    "        ## for the given index_col_vals get only the non-zero indices in an array i.e. only the rows (i.e. images) which has the labels\n",
    "        K = np.where(index_col_vals != 0)[0]\n",
    "        print(\"len(K): {}, K: {}\".format(len(K), K))\n",
    "\n",
    "        ## calculate the total_images_per_label for the selected column i.e. label\n",
    "        T = np.sum(index_col_vals != 0)\n",
    "        print(\"total_images_per_label_col(T): {}\".format(T))\n",
    "\n",
    "        ## must verfiy the total length calculate in different ways must match\n",
    "        assert T == len(K)\n",
    "\n",
    "        ## Check and filter rows(images) which are aleady processed\n",
    "        print(\"len(already_processed_indices), already_processed_indices: {}\".format(len(already_processed_indices), already_processed_indices))\n",
    "        \n",
    "        if len(already_processed_indices) > 0:\n",
    "            K = K[np.where(np.in1d(K,already_processed_indices) < 1 )[0]]\n",
    "            print(\"K: {}\".format(K))\n",
    "            T = len(K)\n",
    "        \n",
    "        if len(K) > 0:\n",
    "            ## Get the split distribution based on the 'T'\n",
    "            ptn, pvl = prcntg[0],prcntg[1]\n",
    "            tn,vl = int(T*ptn), int(T*pvl)\n",
    "            tt = T - tn - vl\n",
    "            print(\"train, val, test splits: {},{},{}\".format(tn, vl, tt))\n",
    "\n",
    "            assert T == tn+vl+tt\n",
    "            print(\"tn, tn+vl, tt: {},{},{}\".format(tn, tn+vl, tt))\n",
    "\n",
    "            ## get the indices per dataset splits\n",
    "            split_pts = [[0,tn-1], [tn,tn+vl-1], [tn+vl,T-1]]\n",
    "            print(\"split_pts: {}\".format(split_pts))\n",
    "\n",
    "            print(\"K[0:tn], K[tn:tn+vl], K[tn+vl:T]: {},{},{}\".format(K[0:tn], K[tn:tn+vl], K[tn+vl:T]))\n",
    "            \n",
    "            if label not in splited_indices:\n",
    "                splited_indices[label] = {}\n",
    "            else:\n",
    "                print(\"label already exists!!! raise Error\")\n",
    "\n",
    "#             splited_indices[label][\"splits\"] = np.array([K[0:tn], K[tn:tn+vl], K[tn+vl:T]])\n",
    "            splited_indices[label][\"splits\"] = [ list(K[0:tn]), list(K[tn:tn+vl]), list(K[tn+vl:T]) ]\n",
    "            splited_indices[label][\"total_images_per_label\"] = total_images_per_label[0]\n",
    "            splited_indices[label][\"label\"] = label\n",
    "            \n",
    "            ## split the indices for the rows i.e. the images which has the labels in the given split percentage\n",
    "            already_processed_indices = np.concatenate((already_processed_indices, K), axis=0)\n",
    "            print(\"len(already_processed_indices), already_processed_indices: {}\".format(len(already_processed_indices), already_processed_indices))\n",
    "            \n",
    "            print(\"splited_indices: {}\".format(splited_indices))\n",
    "            if len(labels) > 0:\n",
    "                print(\"index: {}, labels: {}\".format(index, labels))\n",
    "                labels.pop(index)\n",
    "                print(\"labels: {}\".format(labels))\n",
    "                ## rows for a particular column which has value, make them as zero for all the rows i.e. for the images\n",
    "                tensor[:,index][K[0:tn]] = np.zeros(len(tensor[:,index][K[0:tn]]), dtype=int)\n",
    "                tensor[:,index][K[tn:tn+vl]] = np.zeros(len(tensor[:,index][K[tn:tn+vl]]), dtype=int)\n",
    "                tensor[:,index][K[tn+vl:T]] = np.zeros(len(tensor[:,index][K[tn+vl:T]]), dtype=int)\n",
    "\n",
    "                ## CAUTIOUS: recurssion!!!\n",
    "                tensor = tensor[:,total_images_per_label_sorted_index[1:]]\n",
    "                do_db_split(tensor, labels, splited_indices, already_processed_indices, prcntg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------->\n",
      "tensor.shape: (98, 5)\n",
      "labels to be processed: ['footpath_polygon', 'barricade', 'signage', 'traffic_sign', 'traffic_light']\n",
      "already_processed_indices: []\n",
      "prcntg: [0.7 0.2]\n",
      "Total Images per Label: [85 11 17 18 16]\n",
      "Total Label per Image: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 2 1 1 1 1 2 2 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 3 1 3 2 1 3 2 1 3 2 1\n",
      " 3 2 1 3 3 1 3 2 1 4 1 1 4 2 1 4 2 1 3 2 2 3 2 1]\n",
      "Total Duplication in Images: 49\n",
      "Total Labels: 5\n",
      "Total Annotations per Label: [106  11  17  18  16]\n",
      "Total Annotations: 168\n",
      "Total Images: 98\n",
      "Total Annotations per Image: [1 2 2 1 1 1 1 2 2 1 1 2 2 2 2 1 1 2 2 3 3 1 1 3 3 2 2 1 1 1 1 3 3 1 1 1 1\n",
      " 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 1 4 2 1 3 2 1 3 2 1\n",
      " 3 2 1 3 3 1 3 2 1 4 1 1 4 2 1 4 2 1 3 2 2 3 2 1]\n",
      "total_images_per_label: [85 11 17 18 16]\n",
      "total_images_per_label_sorted_index: [1 4 2 3 0]\n",
      "total_images_per_label[index]: 11\n",
      "index_col_vals: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0]\n",
      "label: barricade\n",
      "len(K): 11, K: [19 20 23 24 25 26 31 32 87 92 95]\n",
      "total_images_per_label_col(T): 11\n",
      "len(already_processed_indices), already_processed_indices: 0\n",
      "train, val, test splits: 7,2,2\n",
      "tn, tn+vl, tt: 7,9,2\n",
      "split_pts: [[0, 6], [7, 8], [9, 10]]\n",
      "K[0:tn], K[tn:tn+vl], K[tn+vl:T]: [19 20 23 24 25 26 31],[32 87],[92 95]\n",
      "len(already_processed_indices), already_processed_indices: 11\n",
      "splited_indices: {'barricade': {'splits': [[19, 20, 23, 24, 25, 26, 31], [32, 87], [92, 95]], 'total_images_per_label': 85, 'label': 'barricade'}}\n",
      "index: 1, labels: ['footpath_polygon', 'barricade', 'signage', 'traffic_sign', 'traffic_light']\n",
      "labels: ['footpath_polygon', 'signage', 'traffic_sign', 'traffic_light']\n",
      "--------------------------------------->\n",
      "tensor.shape: (98, 4)\n",
      "labels to be processed: ['footpath_polygon', 'signage', 'traffic_sign', 'traffic_light']\n",
      "already_processed_indices: [19 20 23 24 25 26 31 32 87 92 95]\n",
      "prcntg: [0.7 0.2]\n",
      "Total Images per Label: [16 17 18 85]\n",
      "Total Label per Image: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 3 1 3 2 1 3 2 1 3 2 1\n",
      " 3 2 1 3 3 1 3 2 1 4 1 1 4 1 1 4 2 1 2 2 2 2 2 1]\n",
      "Total Duplication in Images: 38\n",
      "Total Labels: 4\n",
      "Total Annotations per Label: [ 16  17  18 106]\n",
      "Total Annotations: 157\n",
      "Total Images: 98\n",
      "Total Annotations per Image: [1 2 2 1 1 1 1 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 1 1 1 1 1 1 2 2 1 1 1 1\n",
      " 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 1 4 2 1 3 2 1 3 2 1\n",
      " 3 2 1 3 3 1 3 2 1 4 1 1 4 1 1 4 2 1 2 2 2 2 2 1]\n",
      "total_images_per_label: [16 17 18 85]\n",
      "total_images_per_label_sorted_index: [0 1 2 3]\n",
      "total_images_per_label[index]: 16\n",
      "index_col_vals: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "label: footpath_polygon\n",
      "len(K): 16, K: [82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97]\n",
      "total_images_per_label_col(T): 16\n",
      "len(already_processed_indices), already_processed_indices: 11\n",
      "K: [82 83 84 85 86 88 89 90 91 93 94 96 97]\n",
      "train, val, test splits: 9,2,2\n",
      "tn, tn+vl, tt: 9,11,2\n",
      "split_pts: [[0, 8], [9, 10], [11, 12]]\n",
      "K[0:tn], K[tn:tn+vl], K[tn+vl:T]: [82 83 84 85 86 88 89 90 91],[93 94],[96 97]\n",
      "len(already_processed_indices), already_processed_indices: 24\n",
      "splited_indices: {'barricade': {'splits': [[19, 20, 23, 24, 25, 26, 31], [32, 87], [92, 95]], 'total_images_per_label': 85, 'label': 'barricade'}, 'footpath_polygon': {'splits': [[82, 83, 84, 85, 86, 88, 89, 90, 91], [93, 94], [96, 97]], 'total_images_per_label': 16, 'label': 'footpath_polygon'}}\n",
      "index: 0, labels: ['footpath_polygon', 'signage', 'traffic_sign', 'traffic_light']\n",
      "labels: ['signage', 'traffic_sign', 'traffic_light']\n",
      "--------------------------------------->\n",
      "tensor.shape: (98, 3)\n",
      "labels to be processed: ['signage', 'traffic_sign', 'traffic_light']\n",
      "already_processed_indices: [19 20 23 24 25 26 31 32 87 92 95 82 83 84 85 86 88 89 90 91 93 94 96 97]\n",
      "prcntg: [0.7 0.2]\n",
      "Total Images per Label: [17 18 85]\n",
      "Total Label per Image: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 3 1 3 2 1 3 2 1 3 2 1\n",
      " 3 2 1 3 3 1 3 2 0 3 0 0 3 0 0 3 1 0 1 1 1 1 1 0]\n",
      "Total Duplication in Images: 22\n",
      "Total Labels: 3\n",
      "Total Annotations per Label: [ 17  18 106]\n",
      "Total Annotations: 141\n",
      "Total Images: 98\n",
      "Total Annotations per Image: [1 2 2 1 1 1 1 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 1 1 1 1 1 1 2 2 1 1 1 1\n",
      " 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 1 4 2 1 3 2 1 3 2 1\n",
      " 3 2 1 3 3 1 3 2 0 3 0 0 3 0 0 3 1 0 1 1 1 1 1 0]\n",
      "total_images_per_label: [17 18 85]\n",
      "total_images_per_label_sorted_index: [0 1 2]\n",
      "total_images_per_label[index]: 17\n",
      "index_col_vals: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      "label: signage\n",
      "len(K): 17, K: [61 62 63 65 66 68 69 71 72 74 75 77 78 80 83 86 89]\n",
      "total_images_per_label_col(T): 17\n",
      "len(already_processed_indices), already_processed_indices: 24\n",
      "K: [61 62 63 65 66 68 69 71 72 74 75 77 78 80]\n",
      "train, val, test splits: 9,2,3\n",
      "tn, tn+vl, tt: 9,11,3\n",
      "split_pts: [[0, 8], [9, 10], [11, 13]]\n",
      "K[0:tn], K[tn:tn+vl], K[tn+vl:T]: [61 62 63 65 66 68 69 71 72],[74 75],[77 78 80]\n",
      "len(already_processed_indices), already_processed_indices: 38\n",
      "splited_indices: {'barricade': {'splits': [[19, 20, 23, 24, 25, 26, 31], [32, 87], [92, 95]], 'total_images_per_label': 85, 'label': 'barricade'}, 'footpath_polygon': {'splits': [[82, 83, 84, 85, 86, 88, 89, 90, 91], [93, 94], [96, 97]], 'total_images_per_label': 16, 'label': 'footpath_polygon'}, 'signage': {'splits': [[61, 62, 63, 65, 66, 68, 69, 71, 72], [74, 75], [77, 78, 80]], 'total_images_per_label': 17, 'label': 'signage'}}\n",
      "index: 0, labels: ['signage', 'traffic_sign', 'traffic_light']\n",
      "labels: ['traffic_sign', 'traffic_light']\n",
      "--------------------------------------->\n",
      "tensor.shape: (98, 2)\n",
      "labels to be processed: ['traffic_sign', 'traffic_light']\n",
      "already_processed_indices: [19 20 23 24 25 26 31 32 87 92 95 82 83 84 85 86 88 89 90 91 93 94 96 97\n",
      " 61 62 63 65 66 68 69 71 72 74 75 77 78 80]\n",
      "prcntg: [0.7 0.2]\n",
      "Total Images per Label: [18 85]\n",
      "Total Label per Image: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 2 1 1 2 1 1\n",
      " 2 1 1 2 2 1 2 2 0 2 0 0 2 0 0 2 1 0 1 1 1 1 1 0]\n",
      "Total Duplication in Images: 5\n",
      "Total Labels: 2\n",
      "Total Annotations per Label: [ 18 106]\n",
      "Total Annotations: 124\n",
      "Total Images: 98\n",
      "Total Annotations per Image: [1 2 2 1 1 1 1 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 1 1 1 1 1 1 2 2 1 1 1 1\n",
      " 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 3 1 1 2 1 1 2 1 1\n",
      " 2 1 1 2 2 1 2 2 0 2 0 0 2 0 0 2 1 0 1 1 1 1 1 0]\n",
      "total_images_per_label: [18 85]\n",
      "total_images_per_label_sorted_index: [0 1]\n",
      "total_images_per_label[index]: 18\n",
      "index_col_vals: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 1 1\n",
      " 1 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      "label: traffic_sign\n",
      "len(K): 18, K: [63 65 66 68 69 70 71 72 73 74 75 77 78 80 81 83 86 89]\n",
      "total_images_per_label_col(T): 18\n",
      "len(already_processed_indices), already_processed_indices: 38\n",
      "K: [70 73 81]\n",
      "train, val, test splits: 2,0,1\n",
      "tn, tn+vl, tt: 2,2,1\n",
      "split_pts: [[0, 1], [2, 1], [2, 2]]\n",
      "K[0:tn], K[tn:tn+vl], K[tn+vl:T]: [70 73],[],[81]\n",
      "len(already_processed_indices), already_processed_indices: 41\n",
      "splited_indices: {'barricade': {'splits': [[19, 20, 23, 24, 25, 26, 31], [32, 87], [92, 95]], 'total_images_per_label': 85, 'label': 'barricade'}, 'footpath_polygon': {'splits': [[82, 83, 84, 85, 86, 88, 89, 90, 91], [93, 94], [96, 97]], 'total_images_per_label': 16, 'label': 'footpath_polygon'}, 'signage': {'splits': [[61, 62, 63, 65, 66, 68, 69, 71, 72], [74, 75], [77, 78, 80]], 'total_images_per_label': 17, 'label': 'signage'}, 'traffic_sign': {'splits': [[70, 73], [], [81]], 'total_images_per_label': 18, 'label': 'traffic_sign'}}\n",
      "index: 0, labels: ['traffic_sign', 'traffic_light']\n",
      "labels: ['traffic_light']\n",
      "--------------------------------------->\n",
      "tensor.shape: (98, 1)\n",
      "labels to be processed: ['traffic_light']\n",
      "already_processed_indices: [19 20 23 24 25 26 31 32 87 92 95 82 83 84 85 86 88 89 90 91 93 94 96 97\n",
      " 61 62 63 65 66 68 69 71 72 74 75 77 78 80 70 73 81]\n",
      "prcntg: [0.7 0.2]\n",
      "Total Images per Label: [85]\n",
      "Total Label per Image: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0\n",
      " 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 0]\n",
      "Total Duplication in Images: -13\n",
      "Total Labels: 1\n",
      "Total Annotations per Label: [106]\n",
      "Total Annotations: 106\n",
      "Total Images: 98\n",
      "Total Annotations per Image: [1 2 2 1 1 1 1 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 1 1 1 1 1 1 2 2 1 1 1 1\n",
      " 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 0 1 1 0 0 1 0 0\n",
      " 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 0]\n",
      "total_images_per_label: [85]\n",
      "total_images_per_label_sorted_index: [0]\n",
      "total_images_per_label[index]: 85\n",
      "index_col_vals: [1 2 2 1 1 1 1 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 1 1 1 1 1 1 2 2 1 1 1 1\n",
      " 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 0 1 1 0 0 1 0 0\n",
      " 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 0]\n",
      "label: traffic_light\n",
      "len(K): 85, K: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 67 68 71 74 76 77\n",
      " 78 79 80 81 83 86 89 90 92 93 94 95 96]\n",
      "total_images_per_label_col(T): 85\n",
      "len(already_processed_indices), already_processed_indices: 41\n",
      "K: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 27 28 29\n",
      " 30 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 56 57 58 59 60 64 67 76 79]\n",
      "train, val, test splits: 39,11,7\n",
      "tn, tn+vl, tt: 39,50,7\n",
      "split_pts: [[0, 38], [39, 49], [50, 56]]\n",
      "K[0:tn], K[tn:tn+vl], K[tn+vl:T]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 27 28 29\n",
      " 30 33 34 35 36 37 38 39 40 41 42 43 44 45 46],[47 48 49 50 51 52 53 54 55 56 57],[58 59 60 64 67 76 79]\n",
      "len(already_processed_indices), already_processed_indices: 98\n",
      "splited_indices: {'barricade': {'splits': [[19, 20, 23, 24, 25, 26, 31], [32, 87], [92, 95]], 'total_images_per_label': 85, 'label': 'barricade'}, 'footpath_polygon': {'splits': [[82, 83, 84, 85, 86, 88, 89, 90, 91], [93, 94], [96, 97]], 'total_images_per_label': 16, 'label': 'footpath_polygon'}, 'signage': {'splits': [[61, 62, 63, 65, 66, 68, 69, 71, 72], [74, 75], [77, 78, 80]], 'total_images_per_label': 17, 'label': 'signage'}, 'traffic_sign': {'splits': [[70, 73], [], [81]], 'total_images_per_label': 18, 'label': 'traffic_sign'}, 'traffic_light': {'splits': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46], [47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], [58, 59, 60, 64, 67, 76, 79]], 'total_images_per_label': 85, 'label': 'traffic_light'}}\n",
      "index: 0, labels: ['traffic_light']\n",
      "labels: []\n",
      "--------------------------------------->\n",
      "tensor.shape: (98, 0)\n",
      "labels to be processed: []\n",
      "already_processed_indices: [19 20 23 24 25 26 31 32 87 92 95 82 83 84 85 86 88 89 90 91 93 94 96 97\n",
      " 61 62 63 65 66 68 69 71 72 74 75 77 78 80 70 73 81  0  1  2  3  4  5  6\n",
      "  7  8  9 10 11 12 13 14 15 16 17 18 21 22 27 28 29 30 33 34 35 36 37 38\n",
      " 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 64 67\n",
      " 76 79]\n",
      "prcntg: [0.7 0.2]\n",
      "Total Images per Label: []\n",
      "Total Label per Image: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Total Duplication in Images: -98\n",
      "Total Labels: 0\n",
      "Total Annotations per Label: []\n",
      "Total Annotations: 0\n",
      "Total Images: 98\n",
      "Total Annotations per Image: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "do_db_split(tensor, labels, splited_indices, already_processed_indices, prcntg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splited_indices: {'barricade': {'splits': [[19, 20, 23, 24, 25, 26, 31], [32, 87], [92, 95]], 'total_images_per_label': 85, 'label': 'barricade'}, 'footpath_polygon': {'splits': [[82, 83, 84, 85, 86, 88, 89, 90, 91], [93, 94], [96, 97]], 'total_images_per_label': 16, 'label': 'footpath_polygon'}, 'signage': {'splits': [[61, 62, 63, 65, 66, 68, 69, 71, 72], [74, 75], [77, 78, 80]], 'total_images_per_label': 17, 'label': 'signage'}, 'traffic_sign': {'splits': [[70, 73], [], [81]], 'total_images_per_label': 18, 'label': 'traffic_sign'}, 'traffic_light': {'splits': [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46], [47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], [58, 59, 60, 64, 67, 76, 79]], 'total_images_per_label': 85, 'label': 'traffic_light'}}\n"
     ]
    }
   ],
   "source": [
    "print(\"splited_indices: {}\".format(splited_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'img_id': 'img-dbf4a2c4-374d-4eeb-bed3-4f1d3189b11b', 'annon_dir': '240719_215430/annon_data', 'annotations': ['ant-d4678091-8b23-4bfa-a0d2-807467094716', 'ant-88fafd3e-d04c-42be-a2de-5b3c9070a3db', 'ant-1ce7b6db-dd99-41cf-871f-8f9bf20d9a6f'], 'base_dir': 'images-p1-070619_AT5', 'created_on': '2019-07-24 21:54:32 +05:30', 'dir': 'images/images-p1-070619_AT5', 'file_attributes': {'img_id': 'img-dbf4a2c4-374d-4eeb-bed3-4f1d3189b11b', 'footpath_polygon': 2, 'barricade': 1}, 'file_id': '271218_120802_16717_zed_l_091.jpg1457700', 'filename': '271218_120802_16717_zed_l_091.jpg', 'filepath': '/aimldl-dat/data-gaze/AIML_Annotation/ods_merged_on_050719/images/images-p1-070619_AT5/271218_120802_16717_zed_l_091.jpg', 'height': 1080, 'lbl_ids': ['footpath_polygon', 'footpath_polygon', 'barricade'], 'modified_on': None, 'rel_filename': 'images-p1-070619_AT5_via205_110619.json', 'size': 1457700, 'width': 1920},\n",
       "       {'img_id': 'img-2e7e6acf-ed6e-49cc-b010-d442905423e0', 'annon_dir': '240719_215430/annon_data', 'annotations': ['ant-316508a0-ca8c-4ad2-9cc8-0aa4d8cc63ea', 'ant-7953394c-376e-42c0-952b-65420f4fda5f', 'ant-9d5f0030-4cad-41c3-95d7-2d2fe36bf660'], 'base_dir': 'images-p1-070619_AT5', 'created_on': '2019-07-24 21:54:32 +05:30', 'dir': 'images/images-p1-070619_AT5', 'file_attributes': {'img_id': 'img-2e7e6acf-ed6e-49cc-b010-d442905423e0', 'footpath_polygon': 2, 'barricade': 1}, 'file_id': '271218_120802_16717_zed_l_158.jpg1495507', 'filename': '271218_120802_16717_zed_l_158.jpg', 'filepath': '/aimldl-dat/data-gaze/AIML_Annotation/ods_merged_on_050719/images/images-p1-070619_AT5/271218_120802_16717_zed_l_158.jpg', 'height': 1080, 'lbl_ids': ['footpath_polygon', 'footpath_polygon', 'barricade'], 'modified_on': None, 'rel_filename': 'images-p1-070619_AT5_via205_110619.json', 'size': 1495507, 'width': 1920},\n",
       "       {'img_id': 'img-daedd238-341e-4260-9d76-a73885a2f88e', 'annon_dir': '240719_215430/annon_data', 'annotations': ['ant-6307710d-d580-4a10-965f-f18128403ff6', 'ant-71ea1d39-22e6-4266-bfcb-03159fd66e21', 'ant-a6953738-6534-4d68-971c-92131d83478d'], 'base_dir': 'images-p1-070619_AT5', 'created_on': '2019-07-24 21:54:33 +05:30', 'dir': 'images/images-p1-070619_AT5', 'file_attributes': {'img_id': 'img-daedd238-341e-4260-9d76-a73885a2f88e', 'footpath_polygon': 2, 'barricade': 1}, 'file_id': '271218_120803_16716_zed_l_107.jpg1299237', 'filename': '271218_120803_16716_zed_l_107.jpg', 'filepath': '/aimldl-dat/data-gaze/AIML_Annotation/ods_merged_on_050719/images/images-p1-070619_AT5/271218_120803_16716_zed_l_107.jpg', 'height': 1080, 'lbl_ids': ['footpath_polygon', 'footpath_polygon', 'barricade'], 'modified_on': None, 'rel_filename': 'images-p1-070619_AT5_via205_110619.json', 'size': 1299237, 'width': 1920},\n",
       "       {'img_id': 'img-4443d5ec-c49b-4449-b7ac-1a2e9836e98a', 'annon_dir': '240719_215430/annon_data', 'annotations': ['ant-63820364-8b53-47ee-83e6-9ceb90b3fb14', 'ant-c09a09a1-d22e-468d-9017-5afb5b2bf806', 'ant-e2b741a4-0f83-4dc8-be93-5fee887118c1'], 'base_dir': 'images-p1-070619_AT5', 'created_on': '2019-07-24 21:54:33 +05:30', 'dir': 'images/images-p1-070619_AT5', 'file_attributes': {'img_id': 'img-4443d5ec-c49b-4449-b7ac-1a2e9836e98a', 'footpath_polygon': 2, 'barricade': 1}, 'file_id': '271218_120803_16716_zed_l_240.jpg1307891', 'filename': '271218_120803_16716_zed_l_240.jpg', 'filepath': '/aimldl-dat/data-gaze/AIML_Annotation/ods_merged_on_050719/images/images-p1-070619_AT5/271218_120803_16716_zed_l_240.jpg', 'height': 1080, 'lbl_ids': ['footpath_polygon', 'footpath_polygon', 'barricade'], 'modified_on': None, 'rel_filename': 'images-p1-070619_AT5_via205_110619.json', 'size': 1307891, 'width': 1920},\n",
       "       {'img_id': 'img-364b5b18-f4c1-40cf-9222-bd62abf71fc5', 'annon_dir': '240719_215430/annon_data', 'annotations': ['ant-ec723613-1c5b-4eb9-8f7d-f4920d253aef', 'ant-e2520d3a-9040-4884-aa36-9815af449faf'], 'base_dir': 'images-p1-070619_AT5', 'created_on': '2019-07-24 21:54:33 +05:30', 'dir': 'images/images-p1-070619_AT5', 'file_attributes': {'img_id': 'img-364b5b18-f4c1-40cf-9222-bd62abf71fc5', 'footpath_polygon': 1, 'barricade': 1}, 'file_id': '271218_120803_16717_zed_l_092.jpg1484648', 'filename': '271218_120803_16717_zed_l_092.jpg', 'filepath': '/aimldl-dat/data-gaze/AIML_Annotation/ods_merged_on_050719/images/images-p1-070619_AT5/271218_120803_16717_zed_l_092.jpg', 'height': 1080, 'lbl_ids': ['footpath_polygon', 'barricade'], 'modified_on': None, 'rel_filename': 'images-p1-070619_AT5_via205_110619.json', 'size': 1484648, 'width': 1920},\n",
       "       {'img_id': 'img-f8a0419d-c85a-4df3-bca3-e760f43e3df8', 'annon_dir': '240719_215430/annon_data', 'annotations': ['ant-7b135008-4a83-4b92-beee-cdaa745269bd', 'ant-e0572847-2ef1-4429-93d4-1f1b17ad1dcc'], 'base_dir': 'images-p1-070619_AT5', 'created_on': '2019-07-24 21:54:33 +05:30', 'dir': 'images/images-p1-070619_AT5', 'file_attributes': {'img_id': 'img-f8a0419d-c85a-4df3-bca3-e760f43e3df8', 'barricade': 1, 'footpath_polygon': 1}, 'file_id': '271218_120803_16717_zed_l_158.jpg1489049', 'filename': '271218_120803_16717_zed_l_158.jpg', 'filepath': '/aimldl-dat/data-gaze/AIML_Annotation/ods_merged_on_050719/images/images-p1-070619_AT5/271218_120803_16717_zed_l_158.jpg', 'height': 1080, 'lbl_ids': ['barricade', 'footpath_polygon'], 'modified_on': None, 'rel_filename': 'images-p1-070619_AT5_via205_110619.json', 'size': 1489049, 'width': 1920},\n",
       "       {'img_id': 'img-517716f9-40e2-4614-b2a9-562391515788', 'annon_dir': '240719_215430/annon_data', 'annotations': ['ant-5f7c94f8-0d77-412b-a97a-5c66cc1d6892', 'ant-0bf618c0-6ab6-4459-abd5-6165ffd88503', 'ant-4897f329-5c4e-4bc1-97fc-0e6c8c02cc4e'], 'base_dir': 'images-p1-070619_AT5', 'created_on': '2019-07-24 21:54:33 +05:30', 'dir': 'images/images-p1-070619_AT5', 'file_attributes': {'img_id': 'img-517716f9-40e2-4614-b2a9-562391515788', 'footpath_polygon': 2, 'barricade': 1}, 'file_id': '271218_120804_16717_zed_l_091.jpg1489707', 'filename': '271218_120804_16717_zed_l_091.jpg', 'filepath': '/aimldl-dat/data-gaze/AIML_Annotation/ods_merged_on_050719/images/images-p1-070619_AT5/271218_120804_16717_zed_l_091.jpg', 'height': 1080, 'lbl_ids': ['footpath_polygon', 'barricade', 'footpath_polygon'], 'modified_on': None, 'rel_filename': 'images-p1-070619_AT5_via205_110619.json', 'size': 1489707, 'width': 1920}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[ [19, 20, 23, 24, 25, 26, 31] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
