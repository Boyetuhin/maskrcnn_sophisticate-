{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "from importlib import import_module\n",
    "\n",
    "APP_ROOT_DIR = os.path.join('..')\n",
    "ROOT_DIR = os.path.join(APP_ROOT_DIR,'..')\n",
    "BASE_PATH_CFG = os.path.join(ROOT_DIR,'cfg')\n",
    "\n",
    "# APP_ROOT_DIR = os.getenv('AI_APP')\n",
    "# ROOT_DIR = os.getenv('AI_HOME')\n",
    "# BASE_PATH_CFG = os.getenv('AI_CFG')\n",
    "\n",
    "if APP_ROOT_DIR not in sys.path:\n",
    "  sys.path.append(APP_ROOT_DIR)\n",
    "\n",
    "if BASE_PATH_CFG not in sys.path:\n",
    "  sys.path.append(BASE_PATH_CFG)\n",
    "\n",
    "from _log_ import logcfg\n",
    "log = logging.getLogger(__name__)\n",
    "logging.config.dictConfig(logcfg)\n",
    "\n",
    "import _cfg_\n",
    "import apputil\n",
    "import common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"sys.path: {}\".format(sys.path))\n",
    "\n",
    "cmd = 'evaluate'\n",
    "subset = 'test'\n",
    "iou_threshold = '0.60'\n",
    "\n",
    "# dataset = 'PXL-261019_112629'\n",
    "# exp = 'evaluate-752971b2-e098-456f-9f9e-ec0346483b6f'\n",
    "\n",
    "dataset = 'PXL-171019_185702'\n",
    "exp = 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-04 13:12:56,016:[DEBUG]:[__main__._cfg_]:[_cfg_.py:211 -              loadcfg() ]: ----------------------------->\n",
      "2019-11-04 13:12:56,017:[DEBUG]:[__main__._cfg_]:[_cfg_.py:221 -              loadcfg() ]: ROOT_DIR: /aimldl-cod\n",
      "BASE_PATH_CFG:/aimldl-cfg\n",
      "2019-11-04 13:12:56,017:[DEBUG]:[__main__._cfg_]:[_cfg_.py:226 -              loadcfg() ]: dbname, exp_id:PXL-171019_185702,evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864\n",
      "2019-11-04 13:12:56,037:[DEBUG]:[__main__._cfg_]:[_cfg_.py:188 -          load_appcfg() ]: appcfg: {'PATHS': {'AI_ANNON_DATA_HOME': '/data/samba/Bangalore/prod/Bangalore_Maze_Exported_Data/ANNOTATIONS', 'AI_ANNON_DATA_HOME_LOCAL': '/aimldl-dat/data-gaze/AIML_Annotation/ods_merged_on_240919_121321', 'AI_ANNON_DB': '/aimldl-dat/data-gaze/AIML_Database', 'AI_ANNON_HOME': '/aimldl-cod/apps/annon', 'AI_APP': '/aimldl-cod/apps', 'AI_CFG': '/aimldl-cfg', 'AI_DATA': '/aimldl-dat', 'AI_DOC': '/aimldl-doc', 'AI_GOOGLE_APPLICATION_CREDENTIALS': '/aimldl-cod/auth/', 'AI_HOME': '/aimldl-cod', 'AI_HOME_EXT': '/aimldl-cod/external', 'AI_KBANK': '/aimldl-kbank', 'AI_LANENET_ROOT': '/aimldl-cod/external/lanenet-lane-detection', 'AI_LOGS': '/aimldl-dat/logs', 'AI_MNT': '/aimldl-mnt', 'AI_MODEL_CFG_PATH': '/aimldl-cfg/model', 'AI_PY_ENVVARS': 'AI_APP:AI_HOME_EXT:MASK_RCNN:FASTER_RCNN:CAFFE_ROOT:AI_LANENET_ROOT', 'AI_PY_VENV_PATH': '/home/alpha/virtualmachines/virtualenvs', 'AI_REPORTS': '/aimldl-rpt', 'AI_SCRIPTS': '/aimldl-cod/scripts', 'AI_VM_HOME': '/home/alpha/virtualmachines', 'AI_WEB_APP': '/aimldl-cod/apps/www', 'AI_WEB_APP_LOGS': '/aimldl-dat/logs/www', 'AI_WEB_APP_UPLOADS': '/aimldl-cod/www/uploads', 'AI_WEIGHTS_PATH': '/aimldl-dat/logs', 'AI_WSGIPythonHome': '/home/alpha/virtualmachines/virtualenvs/py_3-6-8_2019-06-26/lib/python3.6/site-packages/', 'AI_WSGIPythonPath': '/home/alpha/virtualmachines/virtualenvs/py_3-6-8_2019-06-26/bin', 'APACHE_HOME': '/home/alpha/public_html', 'CAFFE_ROOT': '/aimldl-cod/external/py-faster-rcnn/caffe-fast-rcnn', 'FASTER_RCNN': '/aimldl-cod/external/py-faster-rcnn', 'MASK_RCNN': '/aimldl-cod/external/Mask_RCNN', 'PYTHONPATH': {'AI_APP': '/aimldl-cod/apps', 'AI_HOME_EXT': '/aimldl-cod/external', 'AI_LANENET_ROOT': '/aimldl-cod/external/lanenet-lane-detection', 'CAFFE_ROOT': '/aimldl-cod/external/py-faster-rcnn/caffe-fast-rcnn', 'FASTER_RCNN': '/aimldl-cod/external/py-faster-rcnn', 'MASK_RCNN': '/aimldl-cod/external/Mask_RCNN'}}, 'APP': {'ALLOWED_FILE_TYPE': ['.txt', '.csv', '.yml', '.json'], 'ALLOWED_IMAGE_TYPE': ['.pdf', '.png', '.jpg', '.jpeg', '.tiff', '.gif'], 'ALLOWED_VIDEO_TYPE': ['.mp4'], 'API_DEFAULT_MODEL_KEY': 'maybeshewill-rld-1', 'API_DOC': {'API_VERSION': 'v2', 'API_VISION_BASE_URL': '/api/vision', 'ARCHS': ['mask_rcnn'], 'DOCS': {'batch_predict': {'deprecated': False, 'description': 'Under Development: Uses queue mechanism for prediction on the images. Input is the array of multipart/form-data images', 'params': {'images': 'array(<multipart/form-data>)', 'q': '<orgname>-<id>-<rel_num>'}, 'type': 'POST', 'url': '<API_VISION_BASE_URL>/<API_VERSION>/predict'}, 'models': {'deprecated': False, 'description': 'Returns the original image', 'examples': {'0': '<API_VISION_BASE_URL>/<API_VERSION>/models', '1': '<API_VISION_BASE_URL>/<API_VERSION>/models/vidteq', '2': '<API_VISION_BASE_URL>/<API_VERSION>/models/vidteq-hmd', '3': '<API_VISION_BASE_URL>/<API_VERSION>/models/vidteq-hmd-1'}, 'params': None, 'type': 'GET', 'url': '<API_VISION_BASE_URL>/<API_VERSION>/models/[ [<orgname>][-<id>][-<rel_num>] ]'}, 'predict': {'deprecated': False, 'description': 'The main api call to make the predictions.', 'examples': {'0': 'curl -X POST -F image=@${image} \"${apiurl}\"'}, 'params': {'image': '<multipart/form-data; >', 'q': '<orgname>-<id>-<rel_num>'}, 'type': 'POST', 'url': '<API_VISION_BASE_URL>/<API_VERSION>/predict'}, 'tdd': {'deprecated': False, 'description': 'Used for test driven development and internal api testing.', 'params': None, 'type': 'POST', 'url': '<API_VISION_BASE_URL>/<API_VERSION>/tdd'}}, 'IDS': {'bsg': 'ballon_segmentation', 'cocop': 'coco_panoptic', 'cocos': 'coco_stuff', 'cocot': 'coco_things', 'hmd': 'hd_map_dataset', 'od': 'object_detection', 'ods': 'object_detection_segmentation', 'pd': 'people_detection', 'road': 'road_segmentation', 'spd': 'sign_post_detection', 'spr': 'sign_post_recognition', 'tsd': 'traffic_sign_detection', 'tsr': 'traffic_sign_recognition'}, 'ORGNAME': ['matterport', 'vidteq', 'mmi']}, 'API_MODELINFO_TABEL': 'MODELINFO', 'API_VERSION': 'v2', 'API_VISION_BASE_URL': '/api/vision', 'API_VISION_URL': '/api/vision/v2', 'APP_NAME': 'falcon', 'ARCH': 'arch', 'ARCHS': ['mask_rcnn'], 'CMD': ['train', 'predict', 'evaluate'], 'DATASET': 'dataset', 'DBCFG': {'ANNONCFG': {'annon_type': 'hmd', 'class_ids': None, 'data_read_threshold': -1, 'dataclass': 'AnnonDataset', 'dbname': 'annon_v3', 'host': 'localhost', 'name': 'hmd', 'password': '', 'port': 27017, 'return_hmd': None, 'username': ''}, 'CBIRCFG': {'dbname': 'eka', 'host': 'localhost', 'password': '', 'port': 27017, 'username': ''}, 'PXLCFG': {'annon_type': 'hmd', 'class_ids': None, 'data_read_threshold': -1, 'dataclass': 'AnnonDataset', 'dbname': 'PXL', 'host': 'localhost', 'name': 'hmd', 'password': '', 'port': 27017, 'return_hmd': None, 'username': ''}, 'REDISCFG': {'batch_size': 1, 'client_max_tries': 100, 'client_sleep': 0.25, 'db': 0, 'host': 'localhost', 'image_dtype': 'float32', 'image_queue': 'image_queue', 'port': 6379, 'server_sleep': 0.25}}, 'DEBUG': False, 'DEVICE': '/gpu:0', 'DOCS': '', 'FILE_DELIMITER': ';', 'GPU_ID': 0, 'HOST': ['10.4.71.69:4040'], 'IDS': {'bsg': 'ballon_segmentation', 'cocop': 'coco_panoptic', 'cocos': 'coco_stuff', 'cocot': 'coco_things', 'hmd': 'hd_map_dataset', 'od': 'object_detection', 'ods': 'object_detection_segmentation', 'pd': 'people_detection', 'road': 'road_segmentation', 'spd': 'sign_post_detection', 'spr': 'sign_post_recognition', 'tsd': 'traffic_sign_detection', 'tsr': 'traffic_sign_recognition'}, 'LOG_TIMESTAMP': False, 'MODE': 'gpu', 'ORGNAME': ['matterport', 'vidteq', 'mmi'], 'ROUTER': 'falcon', 'SAVE_NULL_RESULTS': False, 'TABLES': {'AIDS': [None], 'MODELINFO': [None], 'RELEASE ': [None]}, 'TEST_MODE': 'inference', 'TRAIN_MODE': 'training', 'VIS_DETECTIONS': False, 'WARMUP': False}, 'ARCH': {}, 'DATASET': {}, 'ACTIVE': {'ARCH': '', 'DATASET': ''}}\n",
      "2019-11-04 13:12:56,038:[INFO]:[__main__._cfg_]:[_cfg_.py:192 -          load_appcfg() ]: pythonpath:{'AI_APP': '/aimldl-cod/apps', 'AI_HOME_EXT': '/aimldl-cod/external', 'AI_LANENET_ROOT': '/aimldl-cod/external/lanenet-lane-detection', 'CAFFE_ROOT': '/aimldl-cod/external/py-faster-rcnn/caffe-fast-rcnn', 'FASTER_RCNN': '/aimldl-cod/external/py-faster-rcnn', 'MASK_RCNN': '/aimldl-cod/external/Mask_RCNN'}\n",
      "2019-11-04 13:12:56,038:[DEBUG]:[__main__._cfg_]:[_cfg_.py:194 -          load_appcfg() ]: pythonpath[AI_APP]: /aimldl-cod/apps\n",
      "2019-11-04 13:12:56,039:[DEBUG]:[__main__._cfg_]:[_cfg_.py:194 -          load_appcfg() ]: pythonpath[AI_HOME_EXT]: /aimldl-cod/external\n",
      "2019-11-04 13:12:56,039:[DEBUG]:[__main__._cfg_]:[_cfg_.py:194 -          load_appcfg() ]: pythonpath[AI_LANENET_ROOT]: /aimldl-cod/external/lanenet-lane-detection\n",
      "2019-11-04 13:12:56,039:[DEBUG]:[__main__._cfg_]:[_cfg_.py:194 -          load_appcfg() ]: pythonpath[CAFFE_ROOT]: /aimldl-cod/external/py-faster-rcnn/caffe-fast-rcnn\n",
      "2019-11-04 13:12:56,040:[DEBUG]:[__main__._cfg_]:[_cfg_.py:194 -          load_appcfg() ]: pythonpath[FASTER_RCNN]: /aimldl-cod/external/py-faster-rcnn\n",
      "2019-11-04 13:12:56,040:[DEBUG]:[__main__._cfg_]:[_cfg_.py:194 -          load_appcfg() ]: pythonpath[MASK_RCNN]: /aimldl-cod/external/Mask_RCNN\n",
      "2019-11-04 13:12:56,041:[DEBUG]:[__main__._cfg_]:[_cfg_.py:197 -          load_appcfg() ]: loaded: appcfg.keys(): dict_keys(['PATHS', 'APP', 'ARCH', 'DATASET', 'ACTIVE'])\n",
      "2019-11-04 13:12:56,041:[DEBUG]:[__main__._cfg_]:[_cfg_.py:198 -          load_appcfg() ]: -------\n",
      "2019-11-04 13:12:56,042:[DEBUG]:[__main__._cfg_]:[_cfg_.py:65 -         load_datacfg() ]: ----------------------------->\n",
      "2019-11-04 13:12:56,043:[DEBUG]:[__main__._cfg_]:[_cfg_.py:66 -         load_datacfg() ]: cmd, appcfg, dbname, exp_id, eval_on:  evaluate, {'PATHS': {'AI_ANNON_DATA_HOME': '/data/samba/Bangalore/prod/Bangalore_Maze_Exported_Data/ANNOTATIONS', 'AI_ANNON_DATA_HOME_LOCAL': '/aimldl-dat/data-gaze/AIML_Annotation/ods_merged_on_240919_121321', 'AI_ANNON_DB': '/aimldl-dat/data-gaze/AIML_Database', 'AI_ANNON_HOME': '/aimldl-cod/apps/annon', 'AI_APP': '/aimldl-cod/apps', 'AI_CFG': '/aimldl-cfg', 'AI_DATA': '/aimldl-dat', 'AI_DOC': '/aimldl-doc', 'AI_GOOGLE_APPLICATION_CREDENTIALS': '/aimldl-cod/auth/', 'AI_HOME': '/aimldl-cod', 'AI_HOME_EXT': '/aimldl-cod/external', 'AI_KBANK': '/aimldl-kbank', 'AI_LANENET_ROOT': '/aimldl-cod/external/lanenet-lane-detection', 'AI_LOGS': '/aimldl-dat/logs', 'AI_MNT': '/aimldl-mnt', 'AI_MODEL_CFG_PATH': '/aimldl-cfg/model', 'AI_PY_ENVVARS': 'AI_APP:AI_HOME_EXT:MASK_RCNN:FASTER_RCNN:CAFFE_ROOT:AI_LANENET_ROOT', 'AI_PY_VENV_PATH': '/home/alpha/virtualmachines/virtualenvs', 'AI_REPORTS': '/aimldl-rpt', 'AI_SCRIPTS': '/aimldl-cod/scripts', 'AI_VM_HOME': '/home/alpha/virtualmachines', 'AI_WEB_APP': '/aimldl-cod/apps/www', 'AI_WEB_APP_LOGS': '/aimldl-dat/logs/www', 'AI_WEB_APP_UPLOADS': '/aimldl-cod/www/uploads', 'AI_WEIGHTS_PATH': '/aimldl-dat/logs', 'AI_WSGIPythonHome': '/home/alpha/virtualmachines/virtualenvs/py_3-6-8_2019-06-26/lib/python3.6/site-packages/', 'AI_WSGIPythonPath': '/home/alpha/virtualmachines/virtualenvs/py_3-6-8_2019-06-26/bin', 'APACHE_HOME': '/home/alpha/public_html', 'CAFFE_ROOT': '/aimldl-cod/external/py-faster-rcnn/caffe-fast-rcnn', 'FASTER_RCNN': '/aimldl-cod/external/py-faster-rcnn', 'MASK_RCNN': '/aimldl-cod/external/Mask_RCNN', 'PYTHONPATH': {'AI_APP': '/aimldl-cod/apps', 'AI_HOME_EXT': '/aimldl-cod/external', 'AI_LANENET_ROOT': '/aimldl-cod/external/lanenet-lane-detection', 'CAFFE_ROOT': '/aimldl-cod/external/py-faster-rcnn/caffe-fast-rcnn', 'FASTER_RCNN': '/aimldl-cod/external/py-faster-rcnn', 'MASK_RCNN': '/aimldl-cod/external/Mask_RCNN'}}, 'APP': {'ALLOWED_FILE_TYPE': ['.txt', '.csv', '.yml', '.json'], 'ALLOWED_IMAGE_TYPE': ['.pdf', '.png', '.jpg', '.jpeg', '.tiff', '.gif'], 'ALLOWED_VIDEO_TYPE': ['.mp4'], 'API_DEFAULT_MODEL_KEY': 'maybeshewill-rld-1', 'API_DOC': {'API_VERSION': 'v2', 'API_VISION_BASE_URL': '/api/vision', 'ARCHS': ['mask_rcnn'], 'DOCS': {'batch_predict': {'deprecated': False, 'description': 'Under Development: Uses queue mechanism for prediction on the images. Input is the array of multipart/form-data images', 'params': {'images': 'array(<multipart/form-data>)', 'q': '<orgname>-<id>-<rel_num>'}, 'type': 'POST', 'url': '<API_VISION_BASE_URL>/<API_VERSION>/predict'}, 'models': {'deprecated': False, 'description': 'Returns the original image', 'examples': {'0': '<API_VISION_BASE_URL>/<API_VERSION>/models', '1': '<API_VISION_BASE_URL>/<API_VERSION>/models/vidteq', '2': '<API_VISION_BASE_URL>/<API_VERSION>/models/vidteq-hmd', '3': '<API_VISION_BASE_URL>/<API_VERSION>/models/vidteq-hmd-1'}, 'params': None, 'type': 'GET', 'url': '<API_VISION_BASE_URL>/<API_VERSION>/models/[ [<orgname>][-<id>][-<rel_num>] ]'}, 'predict': {'deprecated': False, 'description': 'The main api call to make the predictions.', 'examples': {'0': 'curl -X POST -F image=@${image} \"${apiurl}\"'}, 'params': {'image': '<multipart/form-data; >', 'q': '<orgname>-<id>-<rel_num>'}, 'type': 'POST', 'url': '<API_VISION_BASE_URL>/<API_VERSION>/predict'}, 'tdd': {'deprecated': False, 'description': 'Used for test driven development and internal api testing.', 'params': None, 'type': 'POST', 'url': '<API_VISION_BASE_URL>/<API_VERSION>/tdd'}}, 'IDS': {'bsg': 'ballon_segmentation', 'cocop': 'coco_panoptic', 'cocos': 'coco_stuff', 'cocot': 'coco_things', 'hmd': 'hd_map_dataset', 'od': 'object_detection', 'ods': 'object_detection_segmentation', 'pd': 'people_detection', 'road': 'road_segmentation', 'spd': 'sign_post_detection', 'spr': 'sign_post_recognition', 'tsd': 'traffic_sign_detection', 'tsr': 'traffic_sign_recognition'}, 'ORGNAME': ['matterport', 'vidteq', 'mmi']}, 'API_MODELINFO_TABEL': 'MODELINFO', 'API_VERSION': 'v2', 'API_VISION_BASE_URL': '/api/vision', 'API_VISION_URL': '/api/vision/v2', 'APP_NAME': 'falcon', 'ARCH': 'arch', 'ARCHS': ['mask_rcnn'], 'CMD': ['train', 'predict', 'evaluate'], 'DATASET': 'dataset', 'DBCFG': {'ANNONCFG': {'annon_type': 'hmd', 'class_ids': None, 'data_read_threshold': -1, 'dataclass': 'AnnonDataset', 'dbname': 'annon_v3', 'host': 'localhost', 'name': 'hmd', 'password': '', 'port': 27017, 'return_hmd': None, 'username': ''}, 'CBIRCFG': {'dbname': 'eka', 'host': 'localhost', 'password': '', 'port': 27017, 'username': ''}, 'PXLCFG': {'annon_type': 'hmd', 'class_ids': None, 'data_read_threshold': -1, 'dataclass': 'AnnonDataset', 'dbname': 'PXL', 'host': 'localhost', 'name': 'hmd', 'password': '', 'port': 27017, 'return_hmd': None, 'username': ''}, 'REDISCFG': {'batch_size': 1, 'client_max_tries': 100, 'client_sleep': 0.25, 'db': 0, 'host': 'localhost', 'image_dtype': 'float32', 'image_queue': 'image_queue', 'port': 6379, 'server_sleep': 0.25}}, 'DEBUG': False, 'DEVICE': '/gpu:0', 'DOCS': '', 'FILE_DELIMITER': ';', 'GPU_ID': 0, 'HOST': ['10.4.71.69:4040'], 'IDS': {'bsg': 'ballon_segmentation', 'cocop': 'coco_panoptic', 'cocos': 'coco_stuff', 'cocot': 'coco_things', 'hmd': 'hd_map_dataset', 'od': 'object_detection', 'ods': 'object_detection_segmentation', 'pd': 'people_detection', 'road': 'road_segmentation', 'spd': 'sign_post_detection', 'spr': 'sign_post_recognition', 'tsd': 'traffic_sign_detection', 'tsr': 'traffic_sign_recognition'}, 'LOG_TIMESTAMP': False, 'MODE': 'gpu', 'ORGNAME': ['matterport', 'vidteq', 'mmi'], 'ROUTER': 'falcon', 'SAVE_NULL_RESULTS': False, 'TABLES': {'AIDS': [None], 'MODELINFO': [None], 'RELEASE ': [None]}, 'TEST_MODE': 'inference', 'TRAIN_MODE': 'training', 'VIS_DETECTIONS': False, 'WARMUP': False}, 'ARCH': {}, 'DATASET': {}, 'ACTIVE': {'ARCH': '', 'DATASET': ''}}, PXL-171019_185702, evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864, test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-04 13:12:56,043:[DEBUG]:[__main__._cfg_]:[_cfg_.py:71 -         load_datacfg() ]: DBCFG, dbname: {'ANNONCFG': {'annon_type': 'hmd', 'class_ids': None, 'data_read_threshold': -1, 'dataclass': 'AnnonDataset', 'dbname': 'annon_v3', 'host': 'localhost', 'name': 'hmd', 'password': '', 'port': 27017, 'return_hmd': None, 'username': ''}, 'CBIRCFG': {'dbname': 'eka', 'host': 'localhost', 'password': '', 'port': 27017, 'username': ''}, 'PXLCFG': {'annon_type': 'hmd', 'class_ids': None, 'data_read_threshold': -1, 'dataclass': 'AnnonDataset', 'dbname': 'PXL', 'host': 'localhost', 'name': 'hmd', 'password': '', 'port': 27017, 'return_hmd': None, 'username': ''}, 'REDISCFG': {'batch_size': 1, 'client_max_tries': 100, 'client_sleep': 0.25, 'db': 0, 'host': 'localhost', 'image_dtype': 'float32', 'image_queue': 'image_queue', 'port': 6379, 'server_sleep': 0.25}}, PXL-171019_185702\n",
      "2019-11-04 13:12:56,044:[DEBUG]:[__main__._cfg_]:[_cfg_.py:104 -         load_datacfg() ]: AI_DATASET_TBLNAME, query: EVALUATE, {'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864'}\n",
      "2019-11-04 13:12:56,048:[DEBUG]:[__main__._cfg_]:[_cfg_.py:111 -         load_datacfg() ]: datacfg: {'created_on': '2019-10-30 09:26:15 +05:30', 'allowed_file_type': ['.txt', '.csv', '.yml', '.json'], 'allowed_image_type': ['.pdf', '.png', '.jpg', '.jpeg', '.gif'], 'allowed_video_type': ['.mp4'], 'annon_type': 'hmd', 'config': {'DETECTION_MIN_CONFIDENCE': 0.8, 'GPU_COUNT': 1, 'IMAGES_PER_GPU': 1, 'IMAGE_MAX_DIM': 1920, 'IMAGE_MIN_DIM': 1080}, 'creator': 'AIE1', 'dataclass': 'AnnonDataset', 'dbname': 'PXL-171019_185702', 'device': '/gpu:0', 'dnnarch': 'mask_rcnn', 'evaluate_no_of_result': -1, 'filename': '221019_18313649-AIE1-2-mask_rcnn.yml', 'filepath': '/aimldl-cfg/arch/221019_18313649-AIE1-2-mask_rcnn.yml', 'framework_type': 'keras', 'iou_threshold': 0.8, 'load_weights': {'by_name': True, 'exclude': ['mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask']}, 'log_dir': 'mask_rcnn/301019_092615', 'mode': 'inference', 'model_info': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'modelinfo': {'checkpoint_path': '/aimldl-dat/logs/mask_rcnn/221019_183347/train_hmd_221019_183930/mask_rcnn_hmd_{epoch:04d}.h5', 'classes': ['BG', 'flyover_pillar', 'pole', 'signage', 'street_light', 'traffic_sign', 'traffic_sign_frame'], 'classinfo': None, 'config': {'DETECTION_MIN_CONFIDENCE': 0.7, 'GPU_COUNT': 1, 'IMAGES_PER_GPU': 1, 'IMAGE_MAX_DIM': 1024, 'IMAGE_MIN_DIM': 800, 'STEPS_PER_EPOCH': 1500}, 'creator': 'AIE1', 'dataset': 'PXL-171019_185702', 'dbname': 'PXL-171019_185702', 'dnnarch': 'mask_rcnn', 'framework_type': 'keras', 'id': None, 'load_weights': {'by_name': True, 'exclude': ['mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask']}, 'log_dir': '/aimldl-dat/logs/mask_rcnn/221019_183347/train_hmd_221019_183930', 'mode': 'inference', 'model_info': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'name': 'hmd', 'num_classes': 7, 'org_name': 'vidteq', 'problem_id': 'ods', 'rel_num': '221019_183931', 'timestamp': '301019_092615', 'weights': None, 'weights_path': 'mask_rcnn/221019_183347/train_hmd_221019_183930/mask_rcnn_hmd_0150.h5', 'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'created_on': '2019-10-30 09:26:15 +05:30', 'filename': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'filepath': '/aimldl-cfg/model/vidteq-hmd-221019_183931-mask_rcnn.yml'}, 'name': 'hmd', 'save_viz_and_json': False, 'splits': ['train', 'val', 'test'], 'test_mode': 'inference', 'timestamp': '301019_092615', 'train_mode': 'training', 'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'weights': None}\n",
      "2019-11-04 13:12:56,049:[DEBUG]:[__main__._cfg_]:[_cfg_.py:119 -         load_archcfg() ]: ----------------------------->\n",
      "2019-11-04 13:12:56,049:[DEBUG]:[__main__._cfg_]:[_cfg_.py:150 -         load_archcfg() ]: DBCFG: {'ANNONCFG': {'annon_type': 'hmd', 'class_ids': None, 'data_read_threshold': -1, 'dataclass': 'AnnonDataset', 'dbname': 'annon_v3', 'host': 'localhost', 'name': 'hmd', 'password': '', 'port': 27017, 'return_hmd': None, 'username': ''}, 'CBIRCFG': {'dbname': 'eka', 'host': 'localhost', 'password': '', 'port': 27017, 'username': ''}, 'PXLCFG': {'annon_type': 'hmd', 'class_ids': None, 'data_read_threshold': -1, 'dataclass': 'AnnonDataset', 'dbname': 'PXL-171019_185702', 'host': 'localhost', 'name': 'hmd', 'password': '', 'port': 27017, 'return_hmd': None, 'username': ''}, 'REDISCFG': {'batch_size': 1, 'client_max_tries': 100, 'client_sleep': 0.25, 'db': 0, 'host': 'localhost', 'image_dtype': 'float32', 'image_queue': 'image_queue', 'port': 6379, 'server_sleep': 0.25}}\n",
      "2019-11-04 13:12:56,050:[DEBUG]:[__main__._cfg_]:[_cfg_.py:151 -         load_archcfg() ]: PXLCFG['dbname'], dbname: PXL-171019_185702, PXL-171019_185702\n",
      "2019-11-04 13:12:56,050:[DEBUG]:[__main__._cfg_]:[_cfg_.py:152 -         load_archcfg() ]: AI_DATASET_TBLNAME, query: EVALUATE, {'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864'}\n",
      "2019-11-04 13:12:56,052:[DEBUG]:[__main__._cfg_]:[_cfg_.py:162 -         load_archcfg() ]: archcfg: {'created_on': '2019-10-30 09:26:15 +05:30', 'allowed_file_type': ['.txt', '.csv', '.yml', '.json'], 'allowed_image_type': ['.pdf', '.png', '.jpg', '.jpeg', '.gif'], 'allowed_video_type': ['.mp4'], 'annon_type': 'hmd', 'config': {'DETECTION_MIN_CONFIDENCE': 0.8, 'GPU_COUNT': 1, 'IMAGES_PER_GPU': 1, 'IMAGE_MAX_DIM': 1920, 'IMAGE_MIN_DIM': 1080}, 'creator': 'AIE1', 'dataclass': 'AnnonDataset', 'dbname': 'PXL-171019_185702', 'device': '/gpu:0', 'dnnarch': 'mask_rcnn', 'evaluate_no_of_result': -1, 'filename': '221019_18313649-AIE1-2-mask_rcnn.yml', 'filepath': '/aimldl-cfg/arch/221019_18313649-AIE1-2-mask_rcnn.yml', 'framework_type': 'keras', 'iou_threshold': 0.8, 'load_weights': {'by_name': True, 'exclude': ['mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask']}, 'log_dir': 'mask_rcnn/301019_092615', 'mode': 'inference', 'model_info': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'modelinfo': {'checkpoint_path': '/aimldl-dat/logs/mask_rcnn/221019_183347/train_hmd_221019_183930/mask_rcnn_hmd_{epoch:04d}.h5', 'classes': ['BG', 'flyover_pillar', 'pole', 'signage', 'street_light', 'traffic_sign', 'traffic_sign_frame'], 'classinfo': None, 'config': {'DETECTION_MIN_CONFIDENCE': 0.7, 'GPU_COUNT': 1, 'IMAGES_PER_GPU': 1, 'IMAGE_MAX_DIM': 1024, 'IMAGE_MIN_DIM': 800, 'STEPS_PER_EPOCH': 1500}, 'creator': 'AIE1', 'dataset': 'PXL-171019_185702', 'dbname': 'PXL-171019_185702', 'dnnarch': 'mask_rcnn', 'framework_type': 'keras', 'id': None, 'load_weights': {'by_name': True, 'exclude': ['mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask']}, 'log_dir': '/aimldl-dat/logs/mask_rcnn/221019_183347/train_hmd_221019_183930', 'mode': 'inference', 'model_info': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'name': 'hmd', 'num_classes': 7, 'org_name': 'vidteq', 'problem_id': 'ods', 'rel_num': '221019_183931', 'timestamp': '301019_092615', 'weights': None, 'weights_path': 'mask_rcnn/221019_183347/train_hmd_221019_183930/mask_rcnn_hmd_0150.h5', 'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'created_on': '2019-10-30 09:26:15 +05:30', 'filename': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'filepath': '/aimldl-cfg/model/vidteq-hmd-221019_183931-mask_rcnn.yml'}, 'name': 'hmd', 'save_viz_and_json': False, 'splits': ['train', 'val', 'test'], 'test_mode': 'inference', 'timestamp': '301019_092615', 'train_mode': 'training', 'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'weights': None}\n",
      "2019-11-04 13:12:56,053:[DEBUG]:[__main__._cfg_]:[_cfg_.py:238 -              loadcfg() ]: appcfg::--------\n",
      "\n",
      "{'PATHS': {'AI_ANNON_DATA_HOME': '/data/samba/Bangalore/prod/Bangalore_Maze_Exported_Data/ANNOTATIONS', 'AI_ANNON_DATA_HOME_LOCAL': '/aimldl-dat/data-gaze/AIML_Annotation/ods_merged_on_240919_121321', 'AI_ANNON_DB': '/aimldl-dat/data-gaze/AIML_Database', 'AI_ANNON_HOME': '/aimldl-cod/apps/annon', 'AI_APP': '/aimldl-cod/apps', 'AI_CFG': '/aimldl-cfg', 'AI_DATA': '/aimldl-dat', 'AI_DOC': '/aimldl-doc', 'AI_GOOGLE_APPLICATION_CREDENTIALS': '/aimldl-cod/auth/', 'AI_HOME': '/aimldl-cod', 'AI_HOME_EXT': '/aimldl-cod/external', 'AI_KBANK': '/aimldl-kbank', 'AI_LANENET_ROOT': '/aimldl-cod/external/lanenet-lane-detection', 'AI_LOGS': '/aimldl-dat/logs', 'AI_MNT': '/aimldl-mnt', 'AI_MODEL_CFG_PATH': '/aimldl-cfg/model', 'AI_PY_ENVVARS': 'AI_APP:AI_HOME_EXT:MASK_RCNN:FASTER_RCNN:CAFFE_ROOT:AI_LANENET_ROOT', 'AI_PY_VENV_PATH': '/home/alpha/virtualmachines/virtualenvs', 'AI_REPORTS': '/aimldl-rpt', 'AI_SCRIPTS': '/aimldl-cod/scripts', 'AI_VM_HOME': '/home/alpha/virtualmachines', 'AI_WEB_APP': '/aimldl-cod/apps/www', 'AI_WEB_APP_LOGS': '/aimldl-dat/logs/www', 'AI_WEB_APP_UPLOADS': '/aimldl-cod/www/uploads', 'AI_WEIGHTS_PATH': '/aimldl-dat/logs', 'AI_WSGIPythonHome': '/home/alpha/virtualmachines/virtualenvs/py_3-6-8_2019-06-26/lib/python3.6/site-packages/', 'AI_WSGIPythonPath': '/home/alpha/virtualmachines/virtualenvs/py_3-6-8_2019-06-26/bin', 'APACHE_HOME': '/home/alpha/public_html', 'CAFFE_ROOT': '/aimldl-cod/external/py-faster-rcnn/caffe-fast-rcnn', 'FASTER_RCNN': '/aimldl-cod/external/py-faster-rcnn', 'MASK_RCNN': '/aimldl-cod/external/Mask_RCNN', 'PYTHONPATH': {'AI_APP': '/aimldl-cod/apps', 'AI_HOME_EXT': '/aimldl-cod/external', 'AI_LANENET_ROOT': '/aimldl-cod/external/lanenet-lane-detection', 'CAFFE_ROOT': '/aimldl-cod/external/py-faster-rcnn/caffe-fast-rcnn', 'FASTER_RCNN': '/aimldl-cod/external/py-faster-rcnn', 'MASK_RCNN': '/aimldl-cod/external/Mask_RCNN'}}, 'APP': {'ALLOWED_FILE_TYPE': ['.txt', '.csv', '.yml', '.json'], 'ALLOWED_IMAGE_TYPE': ['.pdf', '.png', '.jpg', '.jpeg', '.tiff', '.gif'], 'ALLOWED_VIDEO_TYPE': ['.mp4'], 'API_DEFAULT_MODEL_KEY': 'maybeshewill-rld-1', 'API_DOC': {'API_VERSION': 'v2', 'API_VISION_BASE_URL': '/api/vision', 'ARCHS': ['mask_rcnn'], 'DOCS': {'batch_predict': {'deprecated': False, 'description': 'Under Development: Uses queue mechanism for prediction on the images. Input is the array of multipart/form-data images', 'params': {'images': 'array(<multipart/form-data>)', 'q': '<orgname>-<id>-<rel_num>'}, 'type': 'POST', 'url': '<API_VISION_BASE_URL>/<API_VERSION>/predict'}, 'models': {'deprecated': False, 'description': 'Returns the original image', 'examples': {'0': '<API_VISION_BASE_URL>/<API_VERSION>/models', '1': '<API_VISION_BASE_URL>/<API_VERSION>/models/vidteq', '2': '<API_VISION_BASE_URL>/<API_VERSION>/models/vidteq-hmd', '3': '<API_VISION_BASE_URL>/<API_VERSION>/models/vidteq-hmd-1'}, 'params': None, 'type': 'GET', 'url': '<API_VISION_BASE_URL>/<API_VERSION>/models/[ [<orgname>][-<id>][-<rel_num>] ]'}, 'predict': {'deprecated': False, 'description': 'The main api call to make the predictions.', 'examples': {'0': 'curl -X POST -F image=@${image} \"${apiurl}\"'}, 'params': {'image': '<multipart/form-data; >', 'q': '<orgname>-<id>-<rel_num>'}, 'type': 'POST', 'url': '<API_VISION_BASE_URL>/<API_VERSION>/predict'}, 'tdd': {'deprecated': False, 'description': 'Used for test driven development and internal api testing.', 'params': None, 'type': 'POST', 'url': '<API_VISION_BASE_URL>/<API_VERSION>/tdd'}}, 'IDS': {'bsg': 'ballon_segmentation', 'cocop': 'coco_panoptic', 'cocos': 'coco_stuff', 'cocot': 'coco_things', 'hmd': 'hd_map_dataset', 'od': 'object_detection', 'ods': 'object_detection_segmentation', 'pd': 'people_detection', 'road': 'road_segmentation', 'spd': 'sign_post_detection', 'spr': 'sign_post_recognition', 'tsd': 'traffic_sign_detection', 'tsr': 'traffic_sign_recognition'}, 'ORGNAME': ['matterport', 'vidteq', 'mmi']}, 'API_MODELINFO_TABEL': 'MODELINFO', 'API_VERSION': 'v2', 'API_VISION_BASE_URL': '/api/vision', 'API_VISION_URL': '/api/vision/v2', 'APP_NAME': 'falcon', 'ARCH': 'arch', 'ARCHS': ['mask_rcnn'], 'CMD': ['train', 'predict', 'evaluate'], 'DATASET': 'dataset', 'DBCFG': {'ANNONCFG': {'annon_type': 'hmd', 'class_ids': None, 'data_read_threshold': -1, 'dataclass': 'AnnonDataset', 'dbname': 'annon_v3', 'host': 'localhost', 'name': 'hmd', 'password': '', 'port': 27017, 'return_hmd': None, 'username': ''}, 'CBIRCFG': {'dbname': 'eka', 'host': 'localhost', 'password': '', 'port': 27017, 'username': ''}, 'PXLCFG': {'annon_type': 'hmd', 'class_ids': None, 'data_read_threshold': -1, 'dataclass': 'AnnonDataset', 'dbname': 'PXL-171019_185702', 'host': 'localhost', 'name': 'hmd', 'password': '', 'port': 27017, 'return_hmd': None, 'username': ''}, 'REDISCFG': {'batch_size': 1, 'client_max_tries': 100, 'client_sleep': 0.25, 'db': 0, 'host': 'localhost', 'image_dtype': 'float32', 'image_queue': 'image_queue', 'port': 6379, 'server_sleep': 0.25}}, 'DEBUG': False, 'DEVICE': '/gpu:0', 'DOCS': '', 'FILE_DELIMITER': ';', 'GPU_ID': 0, 'HOST': ['10.4.71.69:4040'], 'IDS': {'bsg': 'ballon_segmentation', 'cocop': 'coco_panoptic', 'cocos': 'coco_stuff', 'cocot': 'coco_things', 'hmd': 'hd_map_dataset', 'od': 'object_detection', 'ods': 'object_detection_segmentation', 'pd': 'people_detection', 'road': 'road_segmentation', 'spd': 'sign_post_detection', 'spr': 'sign_post_recognition', 'tsd': 'traffic_sign_detection', 'tsr': 'traffic_sign_recognition'}, 'LOG_TIMESTAMP': False, 'MODE': 'gpu', 'ORGNAME': ['matterport', 'vidteq', 'mmi'], 'ROUTER': 'falcon', 'SAVE_NULL_RESULTS': False, 'TABLES': {'AIDS': [None], 'MODELINFO': [None], 'RELEASE ': [None]}, 'TEST_MODE': 'inference', 'TRAIN_MODE': 'training', 'VIS_DETECTIONS': False, 'WARMUP': False}, 'ARCH': {'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864': {'cfg': {'created_on': '2019-10-30 09:26:15 +05:30', 'allowed_file_type': ['.txt', '.csv', '.yml', '.json'], 'allowed_image_type': ['.pdf', '.png', '.jpg', '.jpeg', '.gif'], 'allowed_video_type': ['.mp4'], 'annon_type': 'hmd', 'config': {'DETECTION_MIN_CONFIDENCE': 0.8, 'GPU_COUNT': 1, 'IMAGES_PER_GPU': 1, 'IMAGE_MAX_DIM': 1920, 'IMAGE_MIN_DIM': 1080}, 'creator': 'AIE1', 'dataclass': 'AnnonDataset', 'dbname': 'PXL-171019_185702', 'device': '/gpu:0', 'dnnarch': 'mask_rcnn', 'evaluate_no_of_result': -1, 'filename': '221019_18313649-AIE1-2-mask_rcnn.yml', 'filepath': '/aimldl-cfg/arch/221019_18313649-AIE1-2-mask_rcnn.yml', 'framework_type': 'keras', 'iou_threshold': 0.8, 'load_weights': {'by_name': True, 'exclude': ['mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask']}, 'log_dir': 'mask_rcnn/301019_092615', 'mode': 'inference', 'model_info': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'modelinfo': {'checkpoint_path': '/aimldl-dat/logs/mask_rcnn/221019_183347/train_hmd_221019_183930/mask_rcnn_hmd_{epoch:04d}.h5', 'classes': ['BG', 'flyover_pillar', 'pole', 'signage', 'street_light', 'traffic_sign', 'traffic_sign_frame'], 'classinfo': None, 'config': {'DETECTION_MIN_CONFIDENCE': 0.7, 'GPU_COUNT': 1, 'IMAGES_PER_GPU': 1, 'IMAGE_MAX_DIM': 1024, 'IMAGE_MIN_DIM': 800, 'STEPS_PER_EPOCH': 1500}, 'creator': 'AIE1', 'dataset': 'PXL-171019_185702', 'dbname': 'PXL-171019_185702', 'dnnarch': 'mask_rcnn', 'framework_type': 'keras', 'id': None, 'load_weights': {'by_name': True, 'exclude': ['mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask']}, 'log_dir': '/aimldl-dat/logs/mask_rcnn/221019_183347/train_hmd_221019_183930', 'mode': 'inference', 'model_info': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'name': 'hmd', 'num_classes': 7, 'org_name': 'vidteq', 'problem_id': 'ods', 'rel_num': '221019_183931', 'timestamp': '301019_092615', 'weights': None, 'weights_path': 'mask_rcnn/221019_183347/train_hmd_221019_183930/mask_rcnn_hmd_0150.h5', 'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'created_on': '2019-10-30 09:26:15 +05:30', 'filename': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'filepath': '/aimldl-cfg/model/vidteq-hmd-221019_183931-mask_rcnn.yml'}, 'name': 'hmd', 'save_viz_and_json': False, 'splits': ['train', 'val', 'test'], 'test_mode': 'inference', 'timestamp': '301019_092615', 'train_mode': 'training', 'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'weights': None}, 'cfg_file': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'cfg_loaded': True}}, 'DATASET': {'PXL-171019_185702': {'cfg': {'created_on': '2019-10-30 09:26:15 +05:30', 'allowed_file_type': ['.txt', '.csv', '.yml', '.json'], 'allowed_image_type': ['.pdf', '.png', '.jpg', '.jpeg', '.gif'], 'allowed_video_type': ['.mp4'], 'annon_type': 'hmd', 'config': {'DETECTION_MIN_CONFIDENCE': 0.8, 'GPU_COUNT': 1, 'IMAGES_PER_GPU': 1, 'IMAGE_MAX_DIM': 1920, 'IMAGE_MIN_DIM': 1080}, 'creator': 'AIE1', 'dataclass': 'AnnonDataset', 'dbname': 'PXL-171019_185702', 'device': '/gpu:0', 'dnnarch': 'mask_rcnn', 'evaluate_no_of_result': -1, 'filename': '221019_18313649-AIE1-2-mask_rcnn.yml', 'filepath': '/aimldl-cfg/arch/221019_18313649-AIE1-2-mask_rcnn.yml', 'framework_type': 'keras', 'iou_threshold': 0.8, 'load_weights': {'by_name': True, 'exclude': ['mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask']}, 'log_dir': 'mask_rcnn/301019_092615', 'mode': 'inference', 'model_info': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'modelinfo': {'checkpoint_path': '/aimldl-dat/logs/mask_rcnn/221019_183347/train_hmd_221019_183930/mask_rcnn_hmd_{epoch:04d}.h5', 'classes': ['BG', 'flyover_pillar', 'pole', 'signage', 'street_light', 'traffic_sign', 'traffic_sign_frame'], 'classinfo': None, 'config': {'DETECTION_MIN_CONFIDENCE': 0.7, 'GPU_COUNT': 1, 'IMAGES_PER_GPU': 1, 'IMAGE_MAX_DIM': 1024, 'IMAGE_MIN_DIM': 800, 'STEPS_PER_EPOCH': 1500}, 'creator': 'AIE1', 'dataset': 'PXL-171019_185702', 'dbname': 'PXL-171019_185702', 'dnnarch': 'mask_rcnn', 'framework_type': 'keras', 'id': None, 'load_weights': {'by_name': True, 'exclude': ['mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask']}, 'log_dir': '/aimldl-dat/logs/mask_rcnn/221019_183347/train_hmd_221019_183930', 'mode': 'inference', 'model_info': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'name': 'hmd', 'num_classes': 7, 'org_name': 'vidteq', 'problem_id': 'ods', 'rel_num': '221019_183931', 'timestamp': '301019_092615', 'weights': None, 'weights_path': 'mask_rcnn/221019_183347/train_hmd_221019_183930/mask_rcnn_hmd_0150.h5', 'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'created_on': '2019-10-30 09:26:15 +05:30', 'filename': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'filepath': '/aimldl-cfg/model/vidteq-hmd-221019_183931-mask_rcnn.yml'}, 'name': 'hmd', 'save_viz_and_json': False, 'splits': ['train', 'val', 'test'], 'test_mode': 'inference', 'timestamp': '301019_092615', 'train_mode': 'training', 'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'weights': None}, 'cfg_file': 'PXL-171019_185702', 'cfg_loaded': True, 'dbcfg': {'annon_type': 'hmd', 'class_ids': None, 'data_read_threshold': -1, 'dataclass': 'AnnonDataset', 'dbname': 'PXL-171019_185702', 'host': 'localhost', 'name': 'hmd', 'password': '', 'port': 27017, 'return_hmd': None, 'username': ''}}}, 'ACTIVE': {'ARCH': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'DATASET': 'PXL-171019_185702'}}\n"
     ]
    }
   ],
   "source": [
    "appcfg = _cfg_.loadcfg(cmd, dataset, exp, subset)\n",
    "datacfg = appcfg.DATASET[appcfg.ACTIVE.DATASET].cfg\n",
    "dbcfg = appcfg.DATASET[appcfg.ACTIVE.DATASET].dbcfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-04 13:12:57,523:[INFO]:[__main__.Base]:[Base.py:38 -             __init__() ]: -------------------------------->\n",
      "2019-11-04 13:12:57,524:[DEBUG]:[__main__.Base]:[Base.py:58 -             __init__() ]: classinfo: [{'source': '', 'id': 0, 'name': 'BG'}]\n",
      "2019-11-04 13:12:57,525:[INFO]:[__main__.Base]:[Base.py:38 -             __init__() ]: -------------------------------->\n",
      "2019-11-04 13:12:57,526:[DEBUG]:[__main__.Base]:[Base.py:58 -             __init__() ]: classinfo: [{'source': '', 'id': 0, 'name': 'BG'}]\n"
     ]
    }
   ],
   "source": [
    "datamod = import_module('utils.'+datacfg.dataclass)\n",
    "datamodcls = getattr(datamod, datacfg.dataclass)\n",
    "name = datacfg.name\n",
    "dataset = datamodcls(name)\n",
    "datamodcls = getattr(datamod, datacfg.dataclass)\n",
    "name = datacfg.name\n",
    "dataset = datamodcls(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-04 13:12:58,667:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:97 -            load_data() ]: --------------------------------> test\n",
      "2019-11-04 13:12:58,667:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:104 -            load_data() ]: load_data:-----> hmd\n",
      "2019-11-04 13:12:58,668:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:109 -            load_data() ]: load_data::fname: load_hmd\n",
      "2019-11-04 13:12:58,669:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:354 -             load_hmd() ]: -------------------------------->\n",
      "2019-11-04 13:12:58,669:[DEBUG]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:355 -             load_hmd() ]: datacfg: {'created_on': '2019-10-30 09:26:15 +05:30', 'allowed_file_type': ['.txt', '.csv', '.yml', '.json'], 'allowed_image_type': ['.pdf', '.png', '.jpg', '.jpeg', '.gif'], 'allowed_video_type': ['.mp4'], 'annon_type': 'hmd', 'config': {'DETECTION_MIN_CONFIDENCE': 0.8, 'GPU_COUNT': 1, 'IMAGES_PER_GPU': 1, 'IMAGE_MAX_DIM': 1920, 'IMAGE_MIN_DIM': 1080}, 'creator': 'AIE1', 'dataclass': 'AnnonDataset', 'dbname': 'PXL-171019_185702', 'device': '/gpu:0', 'dnnarch': 'mask_rcnn', 'evaluate_no_of_result': -1, 'filename': '221019_18313649-AIE1-2-mask_rcnn.yml', 'filepath': '/aimldl-cfg/arch/221019_18313649-AIE1-2-mask_rcnn.yml', 'framework_type': 'keras', 'iou_threshold': 0.8, 'load_weights': {'by_name': True, 'exclude': ['mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask']}, 'log_dir': 'mask_rcnn/301019_092615', 'mode': 'inference', 'model_info': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'modelinfo': {'checkpoint_path': '/aimldl-dat/logs/mask_rcnn/221019_183347/train_hmd_221019_183930/mask_rcnn_hmd_{epoch:04d}.h5', 'classes': ['BG', 'flyover_pillar', 'pole', 'signage', 'street_light', 'traffic_sign', 'traffic_sign_frame'], 'classinfo': None, 'config': {'DETECTION_MIN_CONFIDENCE': 0.7, 'GPU_COUNT': 1, 'IMAGES_PER_GPU': 1, 'IMAGE_MAX_DIM': 1024, 'IMAGE_MIN_DIM': 800, 'STEPS_PER_EPOCH': 1500}, 'creator': 'AIE1', 'dataset': 'PXL-171019_185702', 'dbname': 'PXL-171019_185702', 'dnnarch': 'mask_rcnn', 'framework_type': 'keras', 'id': None, 'load_weights': {'by_name': True, 'exclude': ['mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask']}, 'log_dir': '/aimldl-dat/logs/mask_rcnn/221019_183347/train_hmd_221019_183930', 'mode': 'inference', 'model_info': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'name': 'hmd', 'num_classes': 7, 'org_name': 'vidteq', 'problem_id': 'ods', 'rel_num': '221019_183931', 'timestamp': '301019_092615', 'weights': None, 'weights_path': 'mask_rcnn/221019_183347/train_hmd_221019_183930/mask_rcnn_hmd_0150.h5', 'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'created_on': '2019-10-30 09:26:15 +05:30', 'filename': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'filepath': '/aimldl-cfg/model/vidteq-hmd-221019_183931-mask_rcnn.yml'}, 'name': 'hmd', 'save_viz_and_json': False, 'splits': ['train', 'val', 'test'], 'test_mode': 'inference', 'timestamp': '301019_092615', 'train_mode': 'training', 'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'weights': None}\n",
      "2019-11-04 13:12:58,670:[INFO]:[__main__.annon.dataset.Annon]:[Annon.py:40 -             __init__() ]: -------------------------------->\n",
      "2019-11-04 13:12:58,670:[INFO]:[__main__.annon.dataset.Annon]:[Annon.py:59 -            load_data() ]: -------------------------------->\n",
      "2019-11-04 13:12:58,671:[INFO]:[__main__.annon.dataset.Annon]:[Annon.py:76 -    load_data_from_db() ]: -------------------------------->\n",
      "2019-11-04 13:12:58,671:[DEBUG]:[__main__.annon.dataset.Annon]:[Annon.py:82 -    load_data_from_db() ]: dbcfg: {'annon_type': 'hmd', 'class_ids': None, 'data_read_threshold': -1, 'dataclass': 'AnnonDataset', 'dbname': 'PXL-171019_185702', 'host': 'localhost', 'name': 'hmd', 'password': '', 'port': 27017, 'return_hmd': None, 'username': ''}\n",
      "2019-11-04 13:12:58,901:[INFO]:[__main__.annon.dataset.Annon]:[Annon.py:121 -    load_data_from_db() ]: classinfo: [{'lbl_id': 'flyover_pillar', 'name': 'flyover_pillar', 'source': 'hmd'}, {'lbl_id': 'pole', 'name': 'pole', 'source': 'hmd'}, {'lbl_id': 'signage', 'name': 'signage', 'source': 'hmd'}, {'lbl_id': 'street_light', 'name': 'street_light', 'source': 'hmd'}, {'lbl_id': 'traffic_sign', 'name': 'traffic_sign', 'source': 'hmd'}, {'lbl_id': 'traffic_sign_frame', 'name': 'traffic_sign_frame', 'source': 'hmd'}]\n",
      "2019-11-04 13:12:58,902:[INFO]:[__main__.annon.dataset.Annon]:[Annon.py:130 -    load_data_from_db() ]: len(release): 0\n",
      "2019-11-04 13:12:58,903:[INFO]:[__main__.annon.dataset.Annon]:[Annon.py:168 -          createIndex() ]: -------------------------------->\n",
      "2019-11-04 13:12:58,913:[INFO]:[__main__.annon.dataset.Annon]:[Annon.py:196 -          createIndex() ]: index created!\n",
      "2019-11-04 13:12:58,914:[INFO]:[__main__.annon.dataset.Annon]:[Annon.py:55 -             __init__() ]: Done (t=0.24s)\n",
      "2019-11-04 13:12:58,915:[DEBUG]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:370 -             load_hmd() ]: subset, class_ids: test, ['flyover_pillar', 'pole', 'signage', 'street_light', 'traffic_sign', 'traffic_sign_frame']\n",
      "2019-11-04 13:12:58,915:[DEBUG]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:377 -             load_hmd() ]: data_read_threshold: -1\n",
      "2019-11-04 13:12:58,937:[INFO]:[__main__.annon.dataset.Annon]:[Annon.py:365 -             loadCats() ]: -------------------------------->\n",
      "2019-11-04 13:12:58,937:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:427 -             load_hmd() ]: Adding: class_source, class_lbl_id, class_name, class_dx: hmd, flyover_pillar, flyover_pillar\n",
      "2019-11-04 13:12:58,937:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:427 -             load_hmd() ]: Adding: class_source, class_lbl_id, class_name, class_dx: hmd, pole, pole\n",
      "2019-11-04 13:12:58,938:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:427 -             load_hmd() ]: Adding: class_source, class_lbl_id, class_name, class_dx: hmd, signage, signage\n",
      "2019-11-04 13:12:58,938:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:427 -             load_hmd() ]: Adding: class_source, class_lbl_id, class_name, class_dx: hmd, street_light, street_light\n",
      "2019-11-04 13:12:58,938:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:427 -             load_hmd() ]: Adding: class_source, class_lbl_id, class_name, class_dx: hmd, traffic_sign, traffic_sign\n",
      "2019-11-04 13:12:58,939:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:427 -             load_hmd() ]: Adding: class_source, class_lbl_id, class_name, class_dx: hmd, traffic_sign_frame, traffic_sign_frame\n",
      "2019-11-04 13:12:58,939:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:430 -             load_hmd() ]: Total Images: 1495\n",
      "2019-11-04 13:12:58,939:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:431 -             load_hmd() ]: Total Annotations: 6646\n",
      "2019-11-04 13:12:58,940:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:432 -             load_hmd() ]: Total Classes without BG: 6\n",
      "2019-11-04 13:12:58,940:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:433 -             load_hmd() ]: Total Classes including BG: 7\n",
      "2019-11-04 13:12:58,940:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:434 -             load_hmd() ]: Classinfo: [{'source': '', 'id': 0, 'name': 'BG'}, {'source': 'hmd', 'id': 1, 'lbl_id': 'flyover_pillar', 'name': 'flyover_pillar', 'color': None}, {'source': 'hmd', 'id': 2, 'lbl_id': 'pole', 'name': 'pole', 'color': None}, {'source': 'hmd', 'id': 3, 'lbl_id': 'signage', 'name': 'signage', 'color': None}, {'source': 'hmd', 'id': 4, 'lbl_id': 'street_light', 'name': 'street_light', 'color': None}, {'source': 'hmd', 'id': 5, 'lbl_id': 'traffic_sign', 'name': 'traffic_sign', 'color': None}, {'source': 'hmd', 'id': 6, 'lbl_id': 'traffic_sign_frame', 'name': 'traffic_sign_frame', 'color': None}]\n",
      "2019-11-04 13:12:58,940:[INFO]:[__main__.utils.AnnonDataset]:[AnnonDataset.py:435 -             load_hmd() ]: -------\n",
      "2019-11-04 13:12:58,955:[DEBUG]:[__main__]:[<ipython-input-24-bc967c609acb>:2 -             <module>() ]: total_img, total_annotation, total_classes: 1495, 6646, 6\n"
     ]
    }
   ],
   "source": [
    "total_img, total_annotation, total_classes, annon = dataset.load_data(appcfg, dbcfg, datacfg, subset)\n",
    "log.debug(\"total_img, total_annotation, total_classes: {}, {}, {}\".format(total_img, total_annotation, total_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-04 13:13:03,139:[INFO]:[__main__.Base]:[Base.py:109 -              prepare() ]: -------------------------------->\n",
      "2019-11-04 13:13:03,140:[DEBUG]:[__main__.Base]:[Base.py:117 -              prepare() ]: classinfo: [{'source': '', 'id': 0, 'name': 'BG'}, {'source': 'hmd', 'id': 1, 'lbl_id': 'flyover_pillar', 'name': 'flyover_pillar', 'color': None}, {'source': 'hmd', 'id': 2, 'lbl_id': 'pole', 'name': 'pole', 'color': None}, {'source': 'hmd', 'id': 3, 'lbl_id': 'signage', 'name': 'signage', 'color': None}, {'source': 'hmd', 'id': 4, 'lbl_id': 'street_light', 'name': 'street_light', 'color': None}, {'source': 'hmd', 'id': 5, 'lbl_id': 'traffic_sign', 'name': 'traffic_sign', 'color': None}, {'source': 'hmd', 'id': 6, 'lbl_id': 'traffic_sign_frame', 'name': 'traffic_sign_frame', 'color': None}]\n",
      "2019-11-04 13:13:03,140:[DEBUG]:[__main__.Base]:[Base.py:112 -           clean_name() ]: name: BG\n",
      "2019-11-04 13:13:03,141:[DEBUG]:[__main__.Base]:[Base.py:112 -           clean_name() ]: name: flyover_pillar\n",
      "2019-11-04 13:13:03,141:[DEBUG]:[__main__.Base]:[Base.py:112 -           clean_name() ]: name: pole\n",
      "2019-11-04 13:13:03,141:[DEBUG]:[__main__.Base]:[Base.py:112 -           clean_name() ]: name: signage\n",
      "2019-11-04 13:13:03,141:[DEBUG]:[__main__.Base]:[Base.py:112 -           clean_name() ]: name: street_light\n",
      "2019-11-04 13:13:03,142:[DEBUG]:[__main__.Base]:[Base.py:112 -           clean_name() ]: name: traffic_sign\n",
      "2019-11-04 13:13:03,142:[DEBUG]:[__main__.Base]:[Base.py:112 -           clean_name() ]: name: traffic_sign_frame\n",
      "2019-11-04 13:13:03,142:[DEBUG]:[__main__.Base]:[Base.py:124 -              prepare() ]: self.class_ids[i]: 0\n",
      "2019-11-04 13:13:03,143:[DEBUG]:[__main__.Base]:[Base.py:124 -              prepare() ]: self.class_ids[i]: 1\n",
      "2019-11-04 13:13:03,143:[DEBUG]:[__main__.Base]:[Base.py:124 -              prepare() ]: self.class_ids[i]: 2\n",
      "2019-11-04 13:13:03,143:[DEBUG]:[__main__.Base]:[Base.py:124 -              prepare() ]: self.class_ids[i]: 3\n",
      "2019-11-04 13:13:03,143:[DEBUG]:[__main__.Base]:[Base.py:124 -              prepare() ]: self.class_ids[i]: 4\n",
      "2019-11-04 13:13:03,144:[DEBUG]:[__main__.Base]:[Base.py:124 -              prepare() ]: self.class_ids[i]: 5\n",
      "2019-11-04 13:13:03,144:[DEBUG]:[__main__.Base]:[Base.py:124 -              prepare() ]: self.class_ids[i]: 6\n",
      "2019-11-04 13:13:03,144:[DEBUG]:[__main__.Base]:[Base.py:127 -              prepare() ]: num_classes: 7\n",
      "2019-11-04 13:13:03,145:[DEBUG]:[__main__.Base]:[Base.py:128 -              prepare() ]: class_names: ['BG', 'flyover_pillar', 'pole', 'signage', 'street_light', 'traffic_sign', 'traffic_sign_frame']\n",
      "2019-11-04 13:13:03,145:[DEBUG]:[__main__.Base]:[Base.py:129 -              prepare() ]: class_ids: [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "## Must call before using the dataset\n",
    "\n",
    "dataset.prepare()\n",
    "\n",
    "num_classes = len(dataset.classinfo)\n",
    "num_images = dataset.num_images\n",
    "class_names = [ i['name'] for i in dataset.classinfo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-04 13:13:04,744:[INFO]:[__main__]:[<ipython-input-26-ed295c0e5238>:9 -             <module>() ]: cmdcfg: {'created_on': '2019-10-30 09:26:15 +05:30', 'allowed_file_type': ['.txt', '.csv', '.yml', '.json'], 'allowed_image_type': ['.pdf', '.png', '.jpg', '.jpeg', '.gif'], 'allowed_video_type': ['.mp4'], 'annon_type': 'hmd', 'config': {'DETECTION_MIN_CONFIDENCE': 0.8, 'GPU_COUNT': 1, 'IMAGES_PER_GPU': 1, 'IMAGE_MAX_DIM': 1920, 'IMAGE_MIN_DIM': 1080}, 'creator': 'AIE1', 'dataclass': 'AnnonDataset', 'dbname': 'PXL-171019_185702', 'device': '/gpu:0', 'dnnarch': 'mask_rcnn', 'evaluate_no_of_result': -1, 'filename': '221019_18313649-AIE1-2-mask_rcnn.yml', 'filepath': '/aimldl-cfg/arch/221019_18313649-AIE1-2-mask_rcnn.yml', 'framework_type': 'keras', 'iou_threshold': 0.8, 'load_weights': {'by_name': True, 'exclude': ['mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask']}, 'log_dir': 'mask_rcnn/301019_092615', 'mode': 'inference', 'model_info': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'modelinfo': {'checkpoint_path': '/aimldl-dat/logs/mask_rcnn/221019_183347/train_hmd_221019_183930/mask_rcnn_hmd_{epoch:04d}.h5', 'classes': ['BG', 'flyover_pillar', 'pole', 'signage', 'street_light', 'traffic_sign', 'traffic_sign_frame'], 'classinfo': None, 'config': {'DETECTION_MIN_CONFIDENCE': 0.7, 'GPU_COUNT': 1, 'IMAGES_PER_GPU': 1, 'IMAGE_MAX_DIM': 1024, 'IMAGE_MIN_DIM': 800, 'STEPS_PER_EPOCH': 1500}, 'creator': 'AIE1', 'dataset': 'PXL-171019_185702', 'dbname': 'PXL-171019_185702', 'dnnarch': 'mask_rcnn', 'framework_type': 'keras', 'id': None, 'load_weights': {'by_name': True, 'exclude': ['mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask']}, 'log_dir': '/aimldl-dat/logs/mask_rcnn/221019_183347/train_hmd_221019_183930', 'mode': 'inference', 'model_info': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'name': 'hmd', 'num_classes': 7, 'org_name': 'vidteq', 'problem_id': 'ods', 'rel_num': '221019_183931', 'timestamp': '301019_092615', 'weights': None, 'weights_path': 'mask_rcnn/221019_183347/train_hmd_221019_183930/mask_rcnn_hmd_0150.h5', 'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'created_on': '2019-10-30 09:26:15 +05:30', 'filename': 'vidteq-hmd-221019_183931-mask_rcnn.yml', 'filepath': '/aimldl-cfg/model/vidteq-hmd-221019_183931-mask_rcnn.yml'}, 'name': 'hmd', 'save_viz_and_json': False, 'splits': ['train', 'val', 'test'], 'test_mode': 'inference', 'timestamp': '301019_092615', 'train_mode': 'training', 'uuid': 'evaluate-d6d9d97d-1e0f-4136-a920-02e91ddd7864', 'weights': None}\n"
     ]
    }
   ],
   "source": [
    "name = dataset.name\n",
    "datacfg.name = name\n",
    "datacfg.classes = class_names\n",
    "datacfg.num_classes = num_classes\n",
    "\n",
    "archcfg = appcfg.ARCH[appcfg.ACTIVE.ARCH].cfg\n",
    "cmdcfg = archcfg\n",
    "\n",
    "log.info(\"cmdcfg: {}\".format(cmdcfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-04 13:13:06,504:[INFO]:[__main__]:[<ipython-input-27-487f706c176a>:5 -             <module>() ]: modelcfg_path: /aimldl-cfg/model/vidteq-hmd-221019_183931-mask_rcnn.yml\n",
      "2019-11-04 13:13:06,504:[INFO]:[__main__]:[<ipython-input-27-487f706c176a>:6 -             <module>() ]: cmdcfg.config: {'DETECTION_MIN_CONFIDENCE': 0.8, 'GPU_COUNT': 1, 'IMAGES_PER_GPU': 1, 'IMAGE_MAX_DIM': 1920, 'IMAGE_MIN_DIM': 1080}\n"
     ]
    }
   ],
   "source": [
    "modelcfg_path = os.path.join(appcfg.PATHS.AI_MODEL_CFG_PATH, cmdcfg.model_info)\n",
    "modelcfg = common.yaml_load(modelcfg_path)\n",
    "weights_path = apputil.get_abs_path(appcfg, modelcfg, 'AI_WEIGHTS_PATH')\n",
    "\n",
    "log.info(\"modelcfg_path: {}\".format(modelcfg_path))\n",
    "log.info(\"cmdcfg.config: {}\".format(cmdcfg.config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmdcfg['weights_path'] = weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.8\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1920\n",
      "IMAGE_META_SIZE                13\n",
      "IMAGE_MIN_DIM                  1080\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1920 1920    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           None\n",
      "NUM_CLASSES                    1\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "2019-11-04 13:12:42,231:[INFO]:[__main__.falcon.arch.mask_rcnn]:[mask_rcnn.py:226 -           get_dnncfg() ]: Image size must be dividable by 2 multiple times at least 6 times!\n",
      "2019-11-04 13:12:42,231:[INFO]:[__main__.falcon.arch.mask_rcnn]:[mask_rcnn.py:232 -           get_dnncfg() ]: For Image: WxH=1920x1080 and AP=1.78, re-sized h,w can be: [{'w': 320, 'h': 192, 'ap': 1.67}, {'w': 448, 'h': 256, 'ap': 1.75}, {'w': 576, 'h': 320, 'ap': 1.8}, {'w': 640, 'h': 384, 'ap': 1.67}, {'w': 704, 'h': 384, 'ap': 1.83}, {'w': 768, 'h': 448, 'ap': 1.71}, {'w': 896, 'h': 512, 'ap': 1.75}, {'w': 960, 'h': 576, 'ap': 1.67}, {'w': 1024, 'h': 576, 'ap': 1.78}]\n"
     ]
    }
   ],
   "source": [
    "dnnmod = import_module(\"falcon.arch.\"+cmdcfg.dnnarch)\n",
    "get_dnncfg = getattr(dnnmod, \"get_dnncfg\")\n",
    "dnncfg = get_dnncfg(cmdcfg.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
